<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>GeekIBLi</title>
  
  <subtitle>For Coder</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-07-05T15:09:50.844Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>gaolei</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>elasticsearch映射</title>
    <link href="http://example.com/wiki/elasticsearch%E6%98%A0%E5%B0%84/"/>
    <id>http://example.com/wiki/elasticsearch%E6%98%A0%E5%B0%84/</id>
    <published>2021-07-05T14:54:05.000Z</published>
    <updated>2021-07-05T15:09:50.844Z</updated>
    
    <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>Elasticsearch 支持如下简单域类型：</p><ul><li>字符串: string （es7之后编程text）</li><li>整数 : byte, short, integer, long</li><li>浮点数: float, double</li><li>布尔型: boolean</li><li>日期: date</li></ul><h2 id="查看索引的mapping"><a href="#查看索引的mapping" class="headerlink" title="查看索引的mapping"></a>查看索引的mapping</h2><p><code>GET /gb/_mapping/tweet</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">&quot;gb&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;mappings&quot;</span>: &#123;</span><br><span class="line">         <span class="attr">&quot;tweet&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;properties&quot;</span>: &#123;</span><br><span class="line">               <span class="attr">&quot;date&quot;</span>: &#123;</span><br><span class="line">                  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;date&quot;</span>,</span><br><span class="line">                  <span class="attr">&quot;format&quot;</span>: <span class="string">&quot;strict_date_optional_time||epoch_millis&quot;</span></span><br><span class="line">               &#125;,</span><br><span class="line">               <span class="attr">&quot;name&quot;</span>: &#123;</span><br><span class="line">                  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">               &#125;,</span><br><span class="line">               <span class="attr">&quot;tweet&quot;</span>: &#123;</span><br><span class="line">                  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">               &#125;,</span><br><span class="line">               <span class="attr">&quot;user_id&quot;</span>: &#123;</span><br><span class="line">                  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自定义域映射"><a href="#自定义域映射" class="headerlink" title="自定义域映射"></a>自定义域映射</h2><p>尽管在很多情况下基本域数据类型已经够用，但你经常需要为单独域自定义映射，特别是字符串域。自定义映射允许你执行下面的操作：</p><ul><li>全文字符串域和精确值字符串域的区别</li><li>使用特定语言分析器</li><li>优化域以适应部分匹配</li><li>指定自定义数据格式</li><li>还有更多</li></ul><p>域最重要的属性是 <code>type</code> 。对于不是 string 的域，你一般只需要设置 type ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;number_of_clicks&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;integer&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>默认， <code>string</code> (text) 类型域会被认为包含全文。就是说，它们的值在索引前，会通过一个分析器，针对于这个域的查询在搜索前也会经过一个分析器。</p><p>string 域映射的两个最重要属性是 <code>index</code> 和 <code>analyzer</code> 。</p><h3 id="index"><a href="#index" class="headerlink" title="index"></a>index</h3><p>index 属性控制怎样索引字符串。它可以是下面三个值：</p><h4 id="analyzed"><a href="#analyzed" class="headerlink" title="analyzed"></a>analyzed</h4><p>首先分析字符串，然后索引它。换句话说，以全文索引这个域。</p><h4 id="not-analyzed"><a href="#not-analyzed" class="headerlink" title="not_analyzed"></a>not_analyzed</h4><p>  索引这个域，所以它能够被搜索，但索引的是精确值。不会对它进行分析。</p><h4 id="no"><a href="#no" class="headerlink" title="no"></a>no</h4><p>不索引这个域。这个域不会被搜索到。 (比如一些隐私信息)</p><p>string 域 index 属性默认是 <code>analyzed</code> 。如果我们想映射这个字段为一个精确值，我们需要设置它为 not_analyzed ：</p><p>⚠️ ⚠️<br>其他简单类型（例如 long ， double ， date 等）也接受 index 参数，但有意义的值只有 no 和 not_analyzed ， 因为它们永远不会被分析。  </p><h3 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a>analyzer</h3><p>对于 <code>analyzed</code> 字符串域，用 <code>analyzer</code> 属性指定在搜索和索引时使用的分析器。默认， Elasticsearch 使用 <code>standard</code> 分析器， 但你可以指定一个内置的分析器替代它，例如 <code>whitespace</code> 、 <code>simple</code> 和 <code>english</code>;</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;tweet&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;type&quot;</span>:     <span class="string">&quot;string&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span>: <span class="string">&quot;english&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="更新映射"><a href="#更新映射" class="headerlink" title="更新映射"></a>更新映射</h2><p>当你首次创建一个索引的时候，可以指定类型的映射。你也可以使用 /_mapping 为新类型（或者为存在的类型更新映射）增加映射。<br>⚠️ ⚠️<br>尽管你可以 增加 一个存在的映射，你不能 修改 存在的域映射。如果一个域的映射已经存在，那么该域的数据可能已经被索引。如果你意图修改这个域的映射，索引的数据可能会出错，不能被正常的搜索。</p><p>我们可以更新一个映射来添加一个新域，但不能将一个存在的域从 analyzed 改为 not_analyzed 。</p><p>为了描述指定映射的两种方式，我们先删除 gd 索引：<br><code>DELETE /gb</code><br>然后创建一个新索引，指定 tweet 域使用 english 分析器：  </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PUT /gb </span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;mappings&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;tweet&quot;</span> : &#123;</span><br><span class="line">      <span class="attr">&quot;properties&quot;</span> : &#123;</span><br><span class="line">        <span class="attr">&quot;tweet&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> :    <span class="string">&quot;string&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;analyzer&quot;</span>: <span class="string">&quot;english&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;date&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> :   <span class="string">&quot;date&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;name&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> :   <span class="string">&quot;string&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;user_id&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> :   <span class="string">&quot;long&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>稍后，我们决定在 tweet 映射增加一个新的名为 tag 的 not_analyzed 的文本域，使用 _mapping ：  </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT /gb/_mapping/tweet</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;properties&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;tag&quot;</span> : &#123;</span><br><span class="line">      <span class="attr">&quot;type&quot;</span> :    <span class="string">&quot;string&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;index&quot;</span>:    <span class="string">&quot;not_analyzed&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，我们不需要再次列出所有已存在的域，因为无论如何我们都无法改变它们。新域已经被合并到存在的映射中</p><h2 id="测试映射"><a href="#测试映射" class="headerlink" title="测试映射"></a>测试映射</h2><p>你可以使用 analyze API 测试字符串域的映射。比较下面两个请求的输出：  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /gb/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;field&quot;: &quot;tweet&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Black-cats&quot; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /gb/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;field&quot;: &quot;tag&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Black-cats&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>tweet 域产生两个词条 black 和 cat ， tag 域产生单独的词条 Black-cats 。换句话说，我们的映射正常工作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping-intro.html">Elasticsearch权威指南</a></li><li><a href=""></a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot;&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Elasticsearch 支持如下简单域类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字符串: string （es7之后编程text）&lt;/li&gt;
&lt;li&gt;整数 : </summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    <category term="基本搜索" scheme="http://example.com/categories/Elasticsearch/%E5%9F%BA%E6%9C%AC%E6%90%9C%E7%B4%A2/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>分析与分析器</title>
    <link href="http://example.com/wiki/%E5%88%86%E6%9E%90%E4%B8%8E%E5%88%86%E6%9E%90%E5%99%A8/"/>
    <id>http://example.com/wiki/%E5%88%86%E6%9E%90%E4%B8%8E%E5%88%86%E6%9E%90%E5%99%A8/</id>
    <published>2021-07-05T14:43:44.000Z</published>
    <updated>2021-07-05T15:09:42.888Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>包含下面的过程：</p><p>首先，将一块文本分成适合于倒排索引的独立的 <code>词条</code> ，之后，将这些词条统一化为标准格式以提高它们的“可搜索性”，或者 recall<br>分析器执行上面的工作。 分析器 实际上是将三个功能封装到了一个包里：</p><h3 id="字符过滤器"><a href="#字符过滤器" class="headerlink" title="字符过滤器"></a>字符过滤器</h3><p>首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将 &amp; 转化成 and。</p><h3 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h3><p>其次，字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。</p><h3 id="Token-过滤器"><a href="#Token-过滤器" class="headerlink" title="Token 过滤器"></a>Token 过滤器</h3><p>最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化 Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像 jump 和 leap 这种同义词）。<br>Elasticsearch提供了开箱即用的字符过滤器、分词器和token 过滤器。 这些可以组合起来形成自定义的分析器以用于不同的目的。</p><h2 id="内置分析器"><a href="#内置分析器" class="headerlink" title="内置分析器"></a>内置分析器</h2><p>但是， Elasticsearch还附带了可以直接使用的预包装的分析器。接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：<br><code>&quot;Set the shape to semi-transparent by calling set_trans(5)&quot;</code></p><h3 id="标准分析器"><a href="#标准分析器" class="headerlink" title="标准分析器"></a>标准分析器</h3><p>标准分析器是Elasticsearch默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 Unicode 联盟 定义的 单词边界 划分文本。删除绝大部分标点。最后，将词条小写。它会产生<br><code>set, the, shape, to, semi, transparent, by, calling, set_trans, 5</code></p><h3 id="简单分析器"><a href="#简单分析器" class="headerlink" title="简单分析器"></a>简单分析器</h3><p>简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生<br><code>set, the, shape, to, semi, transparent, by, calling, set, trans</code></p><h3 id="空格分析器"><a href="#空格分析器" class="headerlink" title="空格分析器"></a>空格分析器</h3><p>空格分析器在空格的地方划分文本。它会产生<br><code>Set, the, shape, to, semi-transparent, by, calling, set_trans(5)</code></p><h3 id="语言分析器"><a href="#语言分析器" class="headerlink" title="语言分析器"></a>语言分析器</h3><p>特定语言分析器可用于 很多语言。它们可以考虑指定语言的特点。例如， 英语 分析器附带了一组英语无用词（常用单词，例如 and 或者 the ，它们对相关性没有多少影响），它们会被删除。 由于理解英语语法的规则，这个分词器可以提取英语单词的 词干 。</p><h3 id="英语-分词器会产生下面的词条："><a href="#英语-分词器会产生下面的词条：" class="headerlink" title="英语 分词器会产生下面的词条："></a>英语 分词器会产生下面的词条：</h3><p><code>set, shape, semi, transpar, call, set_tran, 5</code><br>注意看 <code>transparent、</code> <code>calling</code> 和 <code>set_trans</code> 已经变为词根格式。</p><h2 id="什么时候使用分析器"><a href="#什么时候使用分析器" class="headerlink" title="什么时候使用分析器"></a>什么时候使用分析器</h2><p>当我们 <code>索引</code> 一个文档，它的全文域被分析成词条以用来创建倒排索引。 但是，当我们在全文域 搜索 的时候，我们需要将查询字符串通过 相同的分析过程 ，以保证我们搜索的词条格式与索引中的词条格式一致。</p><p>全文查询，理解每个域是如何定义的，因此它们可以做正确的事：</p><p>当你查询一个 <code>全文</code> 域时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。<br>当你查询一个 <code>精确值</code> 域时，不会分析查询字符串，而是搜索你指定的精确值。</p><h2 id="测试分析器"><a href="#测试分析器" class="headerlink" title="测试分析器"></a>测试分析器</h2><p>有些时候很难理解分词的过程和实际被存储到索引中的词条，特别是你刚接触Elasticsearch。为了理解发生了什么，你可以使用 <code>analyze API</code> 来看文本是如何被分析的。在消息体里，指定分析器和要分析的文本：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;analyzer&quot;</span>: <span class="string">&quot;standard&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;Text to analyze&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果中每个元素代表一个单独的词条：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">&quot;tokens&quot;</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;token&quot;</span>:        <span class="string">&quot;text&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;start_offset&quot;</span>: <span class="number">0</span>,</span><br><span class="line">         <span class="attr">&quot;end_offset&quot;</span>:   <span class="number">4</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>:         <span class="string">&quot;&lt;ALPHANUM&gt;&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;position&quot;</span>:     <span class="number">1</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;token&quot;</span>:        <span class="string">&quot;to&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;start_offset&quot;</span>: <span class="number">5</span>,</span><br><span class="line">         <span class="attr">&quot;end_offset&quot;</span>:   <span class="number">7</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>:         <span class="string">&quot;&lt;ALPHANUM&gt;&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;position&quot;</span>:     <span class="number">2</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="attr">&quot;token&quot;</span>:        <span class="string">&quot;analyze&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;start_offset&quot;</span>: <span class="number">8</span>,</span><br><span class="line">         <span class="attr">&quot;end_offset&quot;</span>:   <span class="number">15</span>,</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>:         <span class="string">&quot;&lt;ALPHANUM&gt;&quot;</span>,</span><br><span class="line">         <span class="attr">&quot;position&quot;</span>:     <span class="number">3</span></span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>token</code> 是实际存储到索引中的词条。 <code>position</code> 指明词条在原始文本中出现的位置。 <code>start_offset</code> 和 <code>end_offset</code> 指明字符在原始字符串中的位置。</p><p>每个分析器的 <code>type</code> 值都不一样，可以忽略它们。它们在Elasticsearch中的唯一作用在于​keep_types token 过滤器​。</p><p>analyze API 是一个有用的工具，它有助于我们理解Elasticsearch索引内部发生了什么，随着深入，我们会进一步讨论它。</p><h2 id="指定分析器"><a href="#指定分析器" class="headerlink" title="指定分析器"></a>指定分析器</h2><p>当Elasticsearch在你的文档中检测到一个新的字符串域，它会自动设置其为一个全文 <code>字符串</code> 域，使用 <code>标准</code> 分析器对它进行分析。</p><p>你不希望总是这样。可能你想使用一个不同的分析器，适用于你的数据使用的语言。有时候你想要一个字符串域就是一个字符串域—​不使用分析，直接索引你传入的精确值，例如用户ID或者一个内部的状态域或标签。</p><p>要做到这一点，我们必须手动指定这些域的映射。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;分析&quot;&gt;&lt;a href=&quot;#分析&quot; class=&quot;headerlink&quot; title=&quot;分析&quot;&gt;&lt;/a&gt;分析&lt;/h2&gt;&lt;p&gt;包含下面的过程：&lt;/p&gt;
&lt;p&gt;首先，将一块文本分成适合于倒排索引的独立的 &lt;code&gt;词条&lt;/code&gt; ，之后，将这些词条统一化为标准格</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    <category term="基本搜索" scheme="http://example.com/categories/Elasticsearch/%E5%9F%BA%E6%9C%AC%E6%90%9C%E7%B4%A2/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>倒排索引</title>
    <link href="http://example.com/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    <id>http://example.com/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</id>
    <published>2021-07-05T14:17:00.000Z</published>
    <updated>2021-07-05T14:30:57.743Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。  </p><p>例如，假设我们有两个文档，每个文档的 content 域包含如下内容：  </p><p>The quick brown fox jumped over the lazy dog<br>Quick brown foxes leap over lazy dogs in summer<br>为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 词（我们称它为 词条 或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：</p><img src="https://oscimg.oschina.net/oscnet/up-ea663f731dfb8db97706ffd2d34a2297576.png" width=230 height=300>  <p>现在，如果我们想搜索 <code>quick brown</code> ，我们只需要查找包含每个词条的文档：  </p><img src="https://oscimg.oschina.net/oscnet/up-6b1b6fb36d1467bfab8d222ace66f4f3dc7.png" width=230 height=160>两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。  <p>但是，我们目前的倒排索引有一些问题：</p><p><code>Quick</code> 和 <code>quick</code> 以独立的词条出现，然而用户可能认为它们是相同的词。<br><code>fox</code> 和 <code>foxes</code> 非常相似, 就像 <code>dog</code> 和 <code>dogs</code> ；他们有相同的词根。<br><code>jumped</code> 和 <code>leap</code>, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。<br>使用前面的索引搜索 <code>+Quick</code> <code>+fox</code> 不会得到任何匹配文档。（记住，+ 前缀表明这个词必须存在。）只有同时出现 <code>Quick</code> 和 <code>fox</code> 的文档才满足这个查询条件，但是第一个文档包含 <code>quick fox</code> ，第二个文档包含 <code>Quick foxes</code> 。</p><p>我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。</p><p>如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如：</p><p><code>Quick</code> 可以小写化为 <code>quick</code> 。<br><code>foxes</code> 可以 词干提取 –变为词根的格式– 为 <code>fox</code> 。类似的， <code>dogs</code> 可以为提取为 <code>dog</code> 。<br><code>jumped</code> 和 <code>leap</code> 是同义词，可以索引为相同的单词 <code>jump</code> 。<br>现在索引看上去像这样：<br><img src="https://oscimg.oschina.net/oscnet/up-5ee716c408738e8394f2d9809f8be8354ba.png" width=230 height=270><br>这还远远不够。我们搜索 <code>+Quick</code> <code>+fox</code> 仍然 会失败，因为在我们的索引中，已经没有 <code>Quick</code> 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询 <code>+quick</code> <code>+fox</code> ，这样两个文档都会匹配！</p><p>这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。  &lt;/p&gt;
&lt;p&gt;例如，假设我们有两个文档，每个文档的 content 域包含如下内容：  &lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    <category term="基本搜索" scheme="http://example.com/categories/Elasticsearch/%E5%9F%BA%E6%9C%AC%E6%90%9C%E7%B4%A2/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch分页查询</title>
    <link href="http://example.com/wiki/elasticsearch%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/"/>
    <id>http://example.com/wiki/elasticsearch%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/</id>
    <published>2021-07-05T14:08:23.000Z</published>
    <updated>2021-07-05T14:12:44.958Z</updated>
    
    <content type="html"><![CDATA[<p>和 SQL 使用 LIMIT 关键字返回单个 page 结果的方法相同，Elasticsearch 接受 from 和 size 参数：</p><p><code>size</code><br>显示应该返回的结果数量，默认是 10<br><code>from</code><br>显示应该跳过的初始结果数量，默认是 0<br>如果每页展示 5 条结果，可以用下面方式请求得到 1 到 3 页的结果：</p><p><code>GET /_search?size=5</code><br><code>GET /_search?size=5&amp;from=5</code><br><code>GET /_search?size=5&amp;from=10</code>  </p><p>⚠️ ⚠️ ⚠️<br>考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的。  </p><p>在分布式系统中深度分页</p><blockquote><p>理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。</p></blockquote><p>现在假设我们请求第 1000 页—​结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。</p><p>可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/pagination.html">elasticsearch权威指南</a>  </li><li><a href="https://blog.csdn.net/laoyang360/article/details/116472697?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162549431316780269873046%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=162549431316780269873046&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v29-2-116472697.pc_v2_rank_blog_default&utm_term=%E5%88%86%E9%A1%B5&spm=1018.2226.3001.4450">干货 | 全方位深度解读 Elasticsearch 分页查询</a>  </li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;和 SQL 使用 LIMIT 关键字返回单个 page 结果的方法相同，Elasticsearch 接受 from 和 size 参数：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;size&lt;/code&gt;&lt;br&gt;显示应该返回的结果数量，默认是 10&lt;br&gt;&lt;code&gt;from&lt;/code&gt;&lt;</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    <category term="基本搜索" scheme="http://example.com/categories/Elasticsearch/%E5%9F%BA%E6%9C%AC%E6%90%9C%E7%B4%A2/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>多索引多类型搜索</title>
    <link href="http://example.com/wiki/%E5%A4%9A%E7%B4%A2%E5%BC%95%E5%A4%9A%E7%B1%BB%E5%9E%8B%E6%90%9C%E7%B4%A2/"/>
    <id>http://example.com/wiki/%E5%A4%9A%E7%B4%A2%E5%BC%95%E5%A4%9A%E7%B1%BB%E5%9E%8B%E6%90%9C%E7%B4%A2/</id>
    <published>2021-07-05T14:02:34.000Z</published>
    <updated>2021-07-05T14:07:09.662Z</updated>
    
    <content type="html"><![CDATA[<p>如果不对某一特殊的索引或者类型做限制，就会搜索集群中的所有文档。Elasticsearch 转发搜索请求到每一个主分片或者副本分片，汇集查询出的前10个结果，并且返回给我们。</p><p>然而，经常的情况下，你想在一个或多个特殊的索引并且在一个或者多个特殊的类型中进行搜索。我们可以通过在URL中指定特殊的索引和类型达到这种效果，如下所示：</p><p><code>/_search</code><br>在所有的索引中搜索所有的类型<br><code>/gb/_search</code><br>在 gb 索引中搜索所有的类型<br><code>/gb,us/_search</code><br>在 gb 和 us 索引中搜索所有的文档<br><code>/g*,u*/_search</code><br>在任何以 g 或者 u 开头的索引中搜索所有的类型<br><code>/gb/user/_search</code><br>在 gb 索引中搜索 user 类型<br><code>/gb,us/user,tweet/_search</code><br>在 gb 和 us 索引中搜索 user 和 tweet 类型<br><code>/_all/user,tweet/_search</code><br>在所有的索引中搜索 user 和 tweet 类型<br>当在单一的索引下进行搜索的时候，Elasticsearch 转发请求到索引的每个分片中，可以是主分片也可以是副本分片，然后从每个分片中收集结果。多索引搜索恰好也是用相同的方式工作的—​只是会涉及到更多的分片。  </p><p>注意 ⚠️<br>搜索一个索引有五个主分片和搜索五个索引各有一个分片准确来所说是等价的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如果不对某一特殊的索引或者类型做限制，就会搜索集群中的所有文档。Elasticsearch 转发搜索请求到每一个主分片或者副本分片，汇集查询出的前10个结果，并且返回给我们。&lt;/p&gt;
&lt;p&gt;然而，经常的情况下，你想在一个或多个特殊的索引并且在一个或者多个特殊的类型中进行搜索</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    <category term="基本搜索" scheme="http://example.com/categories/Elasticsearch/%E5%9F%BA%E6%9C%AC%E6%90%9C%E7%B4%A2/"/>
    
    
  </entry>
  
  <entry>
    <title>elasticsearch重要配置</title>
    <link href="http://example.com/wiki/elasticsearch%E9%87%8D%E8%A6%81%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/wiki/elasticsearch%E9%87%8D%E8%A6%81%E9%85%8D%E7%BD%AE/</id>
    <published>2021-07-05T13:22:32.000Z</published>
    <updated>2021-07-05T13:35:52.307Z</updated>
    
    <content type="html"><![CDATA[<p>虽然Elasticsearch仅需要很少的配置，但有许多设置需要手动配置，并且在进入生产之前绝对必须进行配置。</p><p><code>path.data</code> 和 <code>path.logs</code><br><code>cluster.name</code><br><code>node.name</code><br><code>bootstrap.memory_lock</code><br><code>network.host</code><br><code>discovery.zen.ping.unicast.hosts</code><br><code>discovery.zen.minimum_master_nodes</code><br><code>path.data</code> 和 <code>path.logs</code><br>如果使用.zip或.tar.gz归档，则数据和日志目录是$ES_HOME的子文件夹。 如果这些重要的文件夹保留在其默认位置，则存在将Elasticsearch升级到新版本时被删除的高风险。  </p><p>在生产使用中，肯定得更改数据和日志文件夹的位置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">path:</span></span><br><span class="line">  <span class="attr">logs:</span> <span class="string">/var/log/elasticsearch</span></span><br><span class="line">  <span class="attr">data:</span> <span class="string">/var/data/elasticsearch</span></span><br></pre></td></tr></table></figure><p>RPM和Debian发行版已经使用数据和日志的自定义路径。  </p><p><code>path.data</code> 设置可以设置为多个路径，在这种情况下，所有路径将用于存储数据（属于单个分片的文件将全部存储在同一数据路径上）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">path:</span></span><br><span class="line">  <span class="attr">data:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/mnt/elasticsearch_1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/mnt/elasticsearch_2</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/mnt/elasticsearch_3</span></span><br></pre></td></tr></table></figure><h2 id="cluster-name"><a href="#cluster-name" class="headerlink" title="cluster.name"></a>cluster.name</h2><p>节点只能在群集与群集中的所有其他节点共享其cluster.name时才能加入群集。 默认名称为elasticsearch，但您应将其更改为描述集群用途的适当名称。<br><code>cluster.name: logging-prod</code><br>确保不要在不同的环境中重复使用相同的集群名称，否则可能会导致加入错误集群的节点。  </p><h2 id="node-name"><a href="#node-name" class="headerlink" title="node.name"></a>node.name</h2><p>默认情况下，Elasticsearch将使用随机生成的uuid的第一个字符作为节点id。 请注意，节点ID是持久化的，并且在节点重新启动时不会更改，因此默认节点名称也不会更改。<br>配置一个更有意义的名称是值得的，这是重启节点后也能一直保持的优势：<br><code>node.name: prod-data-2</code><br>node.name也可以设置为服务器的HOSTNAME，如下所示：  </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">node.name:</span> <span class="string">$&#123;HOSTNAME&#125;</span></span><br><span class="line"><span class="string">bootstrap.memory_lock</span></span><br></pre></td></tr></table></figure><p>没有JVM被交换到磁盘上这事对于节点的健康来说是至关重要的。一种实现方法是将bootstrap.memory_lock设置为true。<br>要使此设置生效，需要首先配置其他系统设置。 有关如何正确设置内存锁定的更多详细信息，请参阅启用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall">bootstrap.memory_lock</a>。  </p><h2 id="network-host"><a href="#network-host" class="headerlink" title="network.host"></a>network.host</h2><p>默认情况下，Elasticsearch仅仅绑定在本地回路地址——如：127.0.0.1与[::1]。这在一台服务器上跑一个开发节点是足够的。<br>提示</p><p>事实上，多个节点可以在单个节点上相同的$ES_HOME位置一同运行。这可以用于测试Elasticsearch形成集群的能力,但这种配置方式不推荐用于生产环境。</p><p>为了将其它服务器上的节点形成一个可以相互通讯的集群，你的节点将不能绑定在一个回路地址上。 这里有更多的网路配置，通常你只需要配置network.host：<br><code>network.host: 192.168.1.10</code><br>network.host也可以配置成一些能识别的特殊的值，譬如：_local_、_site、_global_，它们可以结合指定:ip4与ip6来使用。更多相信信息请参见：<a href="https://aqlu.gitbooks.io/elasticsearch-reference/content/Modules/Network_Settings.html">网路配置</a></p><p>重要 👇</p><p>一旦你自定义了network.host的配置，Elasticsearch将假设你已经从开发模式转到了生产模式，并将升级系统检测的警告信息为异常信息。更多信息请参见：开发模式vs生产模式</p><h2 id="discovery-zen-ping-unicast-hosts（单播发现）"><a href="#discovery-zen-ping-unicast-hosts（单播发现）" class="headerlink" title="discovery.zen.ping.unicast.hosts（单播发现）"></a>discovery.zen.ping.unicast.hosts（单播发现）</h2><p>开箱即用，无需任何网络配置，Elasticsearch将绑定到可用的回路地址，并扫描9300年到9305的端口去连接同一机器上的其他节点,试图连接到相同的服务器上运行的其他节点。它提供了不需要任何配置就能自动组建集群的体验。<br>当与其它机器上的节点要形成一个集群时，你需要提供一个在线且可访问的节点列表。像如下来配置：  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">   - 192.168.1.10:9300</span><br><span class="line">   - 192.168.1.11 #①</span><br><span class="line">   - seeds.mydomain.com #②</span><br></pre></td></tr></table></figure><p>① 未指定端口时，将使用默认的<code>transport.profiles.default.port</code>值，如果此值也为设置则使用<code>transport.tcp.port</code></p><p>② 主机名将被尝试解析成能解析的多个IP</p><h2 id="discovery-zen-minimum-master-nodes"><a href="#discovery-zen-minimum-master-nodes" class="headerlink" title="discovery.zen.minimum_master_nodes"></a>discovery.zen.minimum_master_nodes</h2><p>为防止数据丢失，配置discovery-zen-minimum_master_nodes将非常重要，他规定了必须至少要有多少个master节点才能形成一个集群。<br>没有此设置时，一个集群在发生网络问题是可能会分裂成多个集群——脑裂——这将导致数据丢失。更多详细信息请参见：通过minimum_master_nodes避免脑裂<br>为避免脑裂，你需要根据master节点数来设置法定人数：<br><code>(master_eligible_nodes / 2) + 1</code><br>换句话说，如果你有三个master节点，最小的主节点数因被设置为(3/2)+1或者是2<br><code>discovery.zen.minimum_master_nodes: 2</code></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall">elastic 官方文档</a></li><li><a href="https://www.codingdict.com/document">codingdict.com</a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;虽然Elasticsearch仅需要很少的配置，但有许多设置需要手动配置，并且在进入生产之前绝对必须进行配置。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;path.data&lt;/code&gt; 和 &lt;code&gt;path.logs&lt;/code&gt;&lt;br&gt;&lt;code&gt;cluster.name&lt;/cod</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch操作索引</title>
    <link href="http://example.com/wiki/elasticsearch%E6%93%8D%E4%BD%9C%E7%B4%A2%E5%BC%95/"/>
    <id>http://example.com/wiki/elasticsearch%E6%93%8D%E4%BD%9C%E7%B4%A2%E5%BC%95/</id>
    <published>2021-07-05T13:11:01.000Z</published>
    <updated>2021-07-05T13:19:41.340Z</updated>
    
    <content type="html"><![CDATA[<h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">PUT customer</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;:&#123;</span><br><span class="line">      &quot;properties&quot;:&#123;</span><br><span class="line">        &quot;id&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">         &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;order_id&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;order_serial&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;order_time&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;date&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;customer_order&quot;:&#123;</span><br><span class="line">          &quot;type&quot;:&quot;join&quot;,</span><br><span class="line">          &quot;relations&quot;:&#123;</span><br><span class="line">            &quot;customer&quot;:&quot;order&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查看索引的mapping"><a href="#查看索引的mapping" class="headerlink" title="查看索引的mapping"></a>查看索引的mapping</h2><p><code>GET yj_visit_data/_mapping</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;yj_visit_data&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;mappings&quot;</span> : &#123;</span><br><span class="line">      <span class="attr">&quot;properties&quot;</span> : &#123;</span><br><span class="line">        <span class="attr">&quot;_class&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> : <span class="string">&quot;text&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;fields&quot;</span> : &#123;</span><br><span class="line">            <span class="attr">&quot;keyword&quot;</span> : &#123;</span><br><span class="line">              <span class="attr">&quot;type&quot;</span> : <span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">              <span class="attr">&quot;ignore_above&quot;</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;article&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span> : <span class="string">&quot;text&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;fields&quot;</span> : &#123;</span><br><span class="line">            <span class="attr">&quot;keyword&quot;</span> : &#123;</span><br><span class="line">              <span class="attr">&quot;type&quot;</span> : <span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">              <span class="attr">&quot;ignore_above&quot;</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查询所有"><a href="#查询所有" class="headerlink" title="查询所有"></a>查询所有</h2><p><code>GET yj_visit_data/_search</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;query&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;match_all&quot;</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="删除所有"><a href="#删除所有" class="headerlink" title="删除所有"></a>删除所有</h2><p><code>POST yj_visit_data/_delete_by_query</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;query&quot;</span>: &#123; </span><br><span class="line">    <span class="attr">&quot;match_all&quot;</span>: &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="通过文章删除"><a href="#通过文章删除" class="headerlink" title="通过文章删除"></a>通过文章删除</h2><p><code>POST yj_visit_data/_delete_by_query</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;query&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;match&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;article.keyword&quot;</span>: <span class="string">&quot;2019/01/3&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="根据文章查询"><a href="#根据文章查询" class="headerlink" title="根据文章查询"></a>根据文章查询</h2><p><code>GET yj_visit_data/_search</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;query&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;match&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;article.keyword&quot;</span>: <span class="string">&quot;2019/01/3&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="修改索引"><a href="#修改索引" class="headerlink" title="修改索引"></a>修改索引</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">POST customer/_doc/<span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;name&quot;</span>:<span class="string">&quot;2&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;创建索引&quot;&gt;&lt;a href=&quot;#创建索引&quot; class=&quot;headerlink&quot; title=&quot;创建索引&quot;&gt;&lt;/a&gt;创建索引&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch基础api</title>
    <link href="http://example.com/wiki/elasticsearch%E5%9F%BA%E7%A1%80cat_api/"/>
    <id>http://example.com/wiki/elasticsearch%E5%9F%BA%E7%A1%80cat_api/</id>
    <published>2021-07-05T12:53:09.000Z</published>
    <updated>2021-07-05T13:10:41.964Z</updated>
    
    <content type="html"><![CDATA[<h2 id="cat-API"><a href="#cat-API" class="headerlink" title="cat API"></a>cat API</h2><h3 id="集群健康状态"><a href="#集群健康状态" class="headerlink" title="集群健康状态"></a>集群健康状态</h3><p>GET _cat/health?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epoch      timestamp cluster        status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line">1625489855 12:57:35  my-application yellow          1         1     35  35    0    0       23             0                  -                 60.3%</span><br></pre></td></tr></table></figure><p>或者直接在服务器上调用rest接口：<br>curl -XGET ‘localhost:9200/_cat/health?v&amp;pretty’</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line">1475247709 17:01:49  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%</span><br></pre></td></tr></table></figure><p>我们可以看到我们名为 my-application 的集群与 yellow 的 status。</p><p>无论何时我们请求集群健康，我们可以获得 green，yellow，或者 red 的 status。Green 表示一切正常（集群功能齐全）， yellow 表示所有数据可用，但是有些副本尚未分配（集群功能齐全），red 意味着由于某些原因有些数据不可用。注意，集群是 red，它仍然具有部分功能（例如，它将继续从可用的分片中服务搜索请求），但是您可能需要尽快去修复它，因为您已经丢失数据了。  </p><p>另外，从上面的响应中，我们可以看到共计 1 个 node（节点）和 0 个 shard（分片），因为我们还没有放入数据的。注意，因为我们使用的是默认的集群名称（elasticsearch），并且 Elasticsearch 默认情况下使用 unicast network（单播网络）来发现同一机器上的其它节点。有可能您不小心在您的电脑上启动了多个节点，然后它们全部加入到了单个集群。在这种情况下，你会在上面的响应中看到不止 1 个 node（节点）。</p><h3 id="查看集群分布"><a href="#查看集群分布" class="headerlink" title="查看集群分布"></a>查看集群分布</h3><p>GET _cat/nodes?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role  master name</span><br><span class="line">172.19.0.1           20          61  15    0.02    0.04     0.29 cdhilmrstw *      redtom-es-1</span><br></pre></td></tr></table></figure><h3 id="查看所有索引"><a href="#查看所有索引" class="headerlink" title="查看所有索引"></a>查看所有索引</h3><p>GET _cat/indices?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">health status index                             uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">yellow open   rd-logstash-2021.06.19            p5iej71MQVW12s2awNv8nw   1   1      61236            0     16.3mb         16.3mb</span><br><span class="line">yellow open   demo_index                        k6VTs7tdS0ysot-rPwxG9A   1   1          1            0      5.5kb          5.5kb</span><br><span class="line">green  open   kibana_sample_data_flights        A7c5DViGSISii8FA0dNlGw   1   0      13059            0      5.6mb          5.6mb</span><br></pre></td></tr></table></figure><h3 id="查看所有索引的数量"><a href="#查看所有索引的数量" class="headerlink" title="查看所有索引的数量"></a>查看所有索引的数量</h3><p>GET _cat/count?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epoch      timestamp count</span><br><span class="line">1625490245 13:04:05  838913</span><br></pre></td></tr></table></figure><h3 id="磁盘分配情况"><a href="#磁盘分配情况" class="headerlink" title="磁盘分配情况"></a>磁盘分配情况</h3><p>GET _cat/allocation?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shards disk.indices disk.used disk.avail disk.total disk.percent host       ip         node</span><br><span class="line">    35      308.7mb    20.1gb    215.9gb    236.1gb            8 172.19.0.1 172.19.0.1 redtom-es-1</span><br><span class="line">    23                                                                                 UNASSIGNED</span><br></pre></td></tr></table></figure><h3 id="查看shard情况"><a href="#查看shard情况" class="headerlink" title="查看shard情况"></a>查看shard情况</h3><p>GET _cat/shards?v&amp;pretty</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">index                             shard prirep state        docs   store ip         node</span><br><span class="line">yj_visit_data                     0     p      STARTED         0    208b 172.19.0.1 redtom-es-1</span><br><span class="line">yj_visit_data                     0     r      UNASSIGNED                           </span><br><span class="line">demo_index                        0     p      STARTED         1   5.5kb 172.19.0.1 redtom-es-1</span><br><span class="line">demo_index                        0     r      UNASSIGNED                           </span><br><span class="line">rbtags                            0     p      STARTED         0    208b 172.19.0.1 redtom-es-1</span><br><span class="line">.kibana_1                         0     p      STARTED       280  11.5mb 172.19.0.1 redtom-es-1</span><br><span class="line">.kibana_task_manager_1            0     p      STARTED         5   5.8mb 172.19.0.1 redtom-es-1</span><br></pre></td></tr></table></figure><p>yj_visit_data 设置了一个副本分区，但是没有副节点，所以节点状态显示未分配；</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.0/cat.html">Elastic 官方文档</a></li><li><a href="https://doc.codingdict.com/elasticsearch/4/">codingdict.com</a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;cat-API&quot;&gt;&lt;a href=&quot;#cat-API&quot; class=&quot;headerlink&quot; title=&quot;cat API&quot;&gt;&lt;/a&gt;cat API&lt;/h2&gt;&lt;h3 id=&quot;集群健康状态&quot;&gt;&lt;a href=&quot;#集群健康状态&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>canal同步mysql数据到elasticsearch</title>
    <link href="http://example.com/wiki/canal%E5%90%8C%E6%AD%A5mysql%E6%95%B0%E6%8D%AE%E5%88%B0elasticsearch/"/>
    <id>http://example.com/wiki/canal%E5%90%8C%E6%AD%A5mysql%E6%95%B0%E6%8D%AE%E5%88%B0elasticsearch/</id>
    <published>2021-07-05T03:26:50.000Z</published>
    <updated>2021-07-05T12:42:57.167Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先安装elk"><a href="#首先安装elk" class="headerlink" title="首先安装elk"></a>首先安装elk</h2><p>推荐大家到elasic中文社区去下载 👉 <a href="https://elasticsearch.cn/">【传送】</a><br>⚠️ elastcisearch | logstash | kibana 的版本最好保持一直，否则会出现很多坑的，切记！</p><p>安装ELK的步骤这里就不做介绍了，可以查看 👉 【TODO】</p><h2 id="下载安装canal-adapter"><a href="#下载安装canal-adapter" class="headerlink" title="下载安装canal-adapter"></a>下载安装canal-adapter</h2><p>canal github传送门 👉  <a href="https://github.com/alibaba/canal">【Alibaba Canal】</a></p><h3 id="canal-client-模式"><a href="#canal-client-模式" class="headerlink" title="canal-client 模式"></a>canal-client 模式</h3><p>可以参照canal给出的example项目和<a href="https://github.com/alibaba/canal/wiki/ClientExample">官方文档</a>给出的例子来测试</p><h4 id="依赖配置"><a href="#依赖配置" class="headerlink" title="依赖配置"></a>依赖配置</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.otter<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>canal.client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="创建maven项目"><a href="#创建maven项目" class="headerlink" title="创建maven项目"></a>创建maven项目</h4><p>保证canal-server 已经正确启动 👈  然后启动下面服务，操作数据库即可看到控制台的日志输出；</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.redtom.canal.deploy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.otter.canal.client.CanalConnector;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.otter.canal.client.CanalConnectors;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.otter.canal.protocol.CanalEntry;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.otter.canal.protocol.Message;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.InitializingBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> gaolei</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2021/6/30 2:57 下午</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CanalClient</span> <span class="keyword">implements</span> <span class="title">InitializingBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> BATCH_SIZE = <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 创建链接</span></span><br><span class="line">        CanalConnector connector = CanalConnectors.newSingleConnector(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;***.***.***.***&quot;</span>, <span class="number">11111</span>),</span><br><span class="line">                <span class="string">&quot;example&quot;</span>, <span class="string">&quot;canal&quot;</span>, <span class="string">&quot;canal&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//打开连接</span></span><br><span class="line">            connector.connect();</span><br><span class="line">            <span class="comment">//订阅数据库表,全部表</span></span><br><span class="line">            connector.subscribe(<span class="string">&quot;.*\\..*&quot;</span>);</span><br><span class="line">            <span class="comment">//回滚到未进行ack的地方，下次fetch的时候，可以从最后一个没有ack的地方开始拿</span></span><br><span class="line">            connector.rollback();</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="comment">// 获取指定数量的数据</span></span><br><span class="line">                Message message = connector.getWithoutAck(BATCH_SIZE);</span><br><span class="line">                <span class="comment">//获取批量ID</span></span><br><span class="line">                <span class="keyword">long</span> batchId = message.getId();</span><br><span class="line">                <span class="comment">//获取批量的数量</span></span><br><span class="line">                <span class="keyword">int</span> size = message.getEntries().size();</span><br><span class="line">                <span class="comment">//如果没有数据</span></span><br><span class="line">                <span class="keyword">if</span> (batchId == -<span class="number">1</span> || size == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="comment">//线程休眠2秒</span></span><br><span class="line">                        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//如果有数据,处理数据</span></span><br><span class="line">                    printEntry(message.getEntries());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//进行 batch id 的确认。确认之后，小于等于此 batchId 的 Message 都会被确认。</span></span><br><span class="line">                connector.ack(batchId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            connector.disconnect();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 打印canal server解析binlog获得的实体类信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printEntry</span><span class="params">(List&lt;CanalEntry.Entry&gt; entrys)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (CanalEntry.Entry entry : entrys) &#123;</span><br><span class="line">            <span class="keyword">if</span> (entry.getEntryType() == CanalEntry.EntryType.TRANSACTIONBEGIN || entry.getEntryType() == CanalEntry.EntryType.TRANSACTIONEND) &#123;</span><br><span class="line">                <span class="comment">//开启/关闭事务的实体类型，跳过</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//RowChange对象，包含了一行数据变化的所有特征</span></span><br><span class="line">            <span class="comment">//比如isDdl 是否是ddl变更操作 sql 具体的ddl sql beforeColumns afterColumns 变更前后的数据字段等等</span></span><br><span class="line">            CanalEntry.RowChange rowChage;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                rowChage = CanalEntry.RowChange.parseFrom(entry.getStoreValue());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;ERROR ## parser of eromanga-event has an error , data:&quot;</span> + entry.toString(), e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//获取操作类型：insert/update/delete类型</span></span><br><span class="line">            CanalEntry.EventType eventType = rowChage.getEventType();</span><br><span class="line">            <span class="comment">//打印Header信息</span></span><br><span class="line">            log.info(<span class="string">&quot;headers:&#123;&#125; &quot;</span>, String.format(<span class="string">&quot;================》; binlog[%s:%s] , name[%s,%s] , eventType : %s&quot;</span>,</span><br><span class="line">                    entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(),</span><br><span class="line">                    entry.getHeader().getSchemaName(), entry.getHeader().getTableName(),</span><br><span class="line">                    eventType));</span><br><span class="line">            <span class="comment">//判断是否是DDL语句</span></span><br><span class="line">            <span class="keyword">if</span> (rowChage.getIsDdl()) &#123;</span><br><span class="line">                log.info(<span class="string">&quot;================》;isDdl: true,sql: &#123;&#125;&quot;</span>, rowChage.getSql());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//获取RowChange对象里的每一行数据，打印出来</span></span><br><span class="line">            <span class="keyword">for</span> (CanalEntry.RowData rowData : rowChage.getRowDatasList()) &#123;</span><br><span class="line">                <span class="comment">//如果是删除语句</span></span><br><span class="line">                <span class="keyword">if</span> (eventType == CanalEntry.EventType.DELETE) &#123;</span><br><span class="line">                    printColumn(rowData.getBeforeColumnsList());</span><br><span class="line">                    <span class="comment">//如果是新增语句</span></span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (eventType == CanalEntry.EventType.INSERT) &#123;</span><br><span class="line">                    printColumn(rowData.getAfterColumnsList());</span><br><span class="line">                    <span class="comment">//如果是更新的语句</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//变更前的数据</span></span><br><span class="line">                    log.info(<span class="string">&quot;-------&gt;; before&quot;</span>);</span><br><span class="line">                    printColumn(rowData.getBeforeColumnsList());</span><br><span class="line">                    <span class="comment">//变更后的数据</span></span><br><span class="line">                    log.info(<span class="string">&quot;-------&gt;; after&quot;</span>);</span><br><span class="line">                    printColumn(rowData.getAfterColumnsList());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printColumn</span><span class="params">(List&lt;CanalEntry.Column&gt; columns)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (CanalEntry.Column column : columns) &#123;</span><br><span class="line">            log.info(<span class="string">&quot; &#123;&#125; :  &#123;&#125;   update= &#123;&#125;&quot;</span>, column.getName(), column.getValue(), column.getUpdated());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="canal-adapter-模式"><a href="#canal-adapter-模式" class="headerlink" title="canal-adapter 模式"></a>canal-adapter 模式</h3><p>adapter 配置文件如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">jackson:</span></span><br><span class="line">    <span class="attr">date-format:</span> <span class="string">yyyy-MM-dd</span> <span class="string">HH:mm:ss</span></span><br><span class="line">    <span class="attr">time-zone:</span> <span class="string">GMT+8</span></span><br><span class="line">    <span class="attr">default-property-inclusion:</span> <span class="string">non_null</span></span><br><span class="line"></span><br><span class="line"><span class="attr">canal.conf:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">tcp</span> <span class="comment">#tcp kafka rocketMQ rabbitMQ</span></span><br><span class="line">  <span class="attr">flatMessage:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">zookeeperHosts:</span></span><br><span class="line">  <span class="attr">syncBatchSize:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">batchSize:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">retries:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">timeout:</span></span><br><span class="line">  <span class="attr">accessKey:</span></span><br><span class="line">  <span class="attr">secretKey:</span></span><br><span class="line">  <span class="attr">consumerProperties:</span></span><br><span class="line">    <span class="comment"># canal tcp consumer</span></span><br><span class="line">    <span class="attr">canal.tcp.server.host:</span> <span class="number">172.25</span><span class="number">.101</span><span class="number">.75</span><span class="string">:11111</span></span><br><span class="line">    <span class="attr">canal.tcp.zookeeper.hosts:</span></span><br><span class="line">    <span class="attr">canal.tcp.batch.size:</span> <span class="number">500</span></span><br><span class="line">    <span class="attr">canal.tcp.username:</span></span><br><span class="line">    <span class="attr">canal.tcp.password:</span></span><br><span class="line">  <span class="attr">srcDataSources:</span></span><br><span class="line">    <span class="attr">defaultDS:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">jdbc:mysql://xxxx:pppp/database?useUnicode=true</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">pwd</span></span><br><span class="line">  <span class="attr">canalAdapters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">instance:</span> <span class="string">example</span> <span class="comment"># canal instance Name or mq topic name</span></span><br><span class="line">    <span class="attr">groups:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">groupId:</span> <span class="string">g1</span></span><br><span class="line">      <span class="attr">outerAdapters:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logger</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">es7</span></span><br><span class="line">        <span class="attr">hosts:</span> <span class="number">172.25</span><span class="number">.101</span><span class="number">.75</span><span class="string">:9300</span> <span class="comment"># 127.0.0.1:9200 for rest mode</span></span><br><span class="line">        <span class="attr">properties:</span></span><br><span class="line">          <span class="attr">mode:</span> <span class="string">transport</span> <span class="comment"># or rest</span></span><br><span class="line"><span class="comment">#          # security.auth: test:123456 #  only used for rest mode</span></span><br><span class="line">          <span class="attr">cluster.name:</span> <span class="string">my-application</span></span><br><span class="line"><span class="comment">#        - name: kudu</span></span><br><span class="line"><span class="comment">#          key: kudu</span></span><br><span class="line"><span class="comment">#          properties:</span></span><br><span class="line"><span class="comment">#            kudu.master.address: 127.0.0.1 # &#x27;,&#x27; split multi address</span></span><br></pre></td></tr></table></figure><p>我的elasticsearch是7.10.0版本的<br><code>application.yml  bootstrap.yml  es6  es7  hbase  kudu  logback.xml  META-INF  rdb</code><br>所以：👇</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd es7</span><br><span class="line">biz_order.yml  customer.yml  mytest_user.yml</span><br><span class="line">vim customer.yml</span><br></pre></td></tr></table></figure><p>customer.yml 配置文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSourceKey:</span> <span class="string">defaultDS</span></span><br><span class="line"><span class="attr">destination:</span> <span class="string">example</span></span><br><span class="line"><span class="attr">groupId:</span> <span class="string">g1</span></span><br><span class="line"><span class="attr">esMapping:</span></span><br><span class="line">  <span class="attr">_index:</span> <span class="string">customer</span></span><br><span class="line">  <span class="attr">_id:</span> <span class="string">id</span></span><br><span class="line">  <span class="attr">relations:</span></span><br><span class="line">    <span class="attr">customer_order:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">customer</span></span><br><span class="line">  <span class="attr">sql:</span> <span class="string">&quot;select t.id, t.name, t.email from customer t&quot;</span></span><br><span class="line">  <span class="attr">etlCondition:</span> <span class="string">&quot;where t.c_time&gt;=&#123;&#125;&quot;</span></span><br><span class="line">  <span class="attr">commitBatch:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure><h4 id="创建表结构"><a href="#创建表结构" class="headerlink" title="创建表结构"></a>创建表结构</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `customer` (</span><br><span class="line">  `id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `email` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `order_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `order_serial` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `order_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `customer_order` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `c_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span></span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4;</span><br></pre></td></tr></table></figure><h4 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">PUT customer</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;mappings&quot;</span>:&#123;</span><br><span class="line">      <span class="attr">&quot;properties&quot;</span>:&#123;</span><br><span class="line">        <span class="attr">&quot;id&quot;</span>: &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;name&quot;</span>: &#123;</span><br><span class="line">         <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;email&quot;</span>: &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;order_id&quot;</span>: &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;order_serial&quot;</span>: &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;order_time&quot;</span>: &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;date&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;customer_order&quot;</span>:&#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;</span>:<span class="string">&quot;join&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;relations&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;customer&quot;</span>:<span class="string">&quot;order&quot;</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="测试canal-adapter同步效果"><a href="#测试canal-adapter同步效果" class="headerlink" title="测试canal-adapter同步效果"></a>测试canal-adapter同步效果</h4><h5 id="创建一条记录"><a href="#创建一条记录" class="headerlink" title="创建一条记录"></a>创建一条记录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-07-05 11:50:53.725 [pool-3-thread-1] DEBUG c.a.o.canal.client.adapter.es.core.service.ESSyncService - DML: &#123;&quot;data&quot;:[&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;1&quot;,&quot;email&quot;:&quot;1&quot;,&quot;order_id&quot;:1,&quot;order_serial&quot;:&quot;1&quot;,&quot;order_time&quot;:1625457046000,&quot;customer_order&quot;:&quot;1&quot;,&quot;c_time&quot;:1625457049000&#125;],&quot;database&quot;:&quot;redtom_dev&quot;,&quot;destination&quot;:&quot;example&quot;,&quot;es&quot;:1625457053000,&quot;groupId&quot;:&quot;g1&quot;,&quot;isDdl&quot;:false,&quot;old&quot;:null,&quot;pkNames&quot;:[],&quot;sql&quot;:&quot;&quot;,&quot;table&quot;:&quot;customer&quot;,&quot;ts&quot;:1625457053724,&quot;type&quot;:&quot;INSERT&quot;&#125;</span><br><span class="line">Affected indexes: customer</span><br></pre></td></tr></table></figure><p>Elastcisearch 效果</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;took&quot;</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">&quot;timed_out&quot;</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">&quot;_shards&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;total&quot;</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;successful&quot;</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;skipped&quot;</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;failed&quot;</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">&quot;hits&quot;</span> : &#123;</span><br><span class="line">    <span class="attr">&quot;total&quot;</span> : &#123;</span><br><span class="line">      <span class="attr">&quot;value&quot;</span> : <span class="number">1</span>,</span><br><span class="line">      <span class="attr">&quot;relation&quot;</span> : <span class="string">&quot;eq&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;max_score&quot;</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="attr">&quot;hits&quot;</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;_index&quot;</span> : <span class="string">&quot;customer&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;_type&quot;</span> : <span class="string">&quot;_doc&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;_id&quot;</span> : <span class="string">&quot;1&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;_score&quot;</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">&quot;_source&quot;</span> : &#123;</span><br><span class="line">          <span class="attr">&quot;name&quot;</span> : <span class="string">&quot;1&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;email&quot;</span> : <span class="string">&quot;1&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;customer_order&quot;</span> : &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span> : <span class="string">&quot;customer&quot;</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-07-05 11:54:36.402 [pool-3-thread-1] DEBUG c.a.o.canal.client.adapter.es.core.service.ESSyncService - DML: &#123;&quot;data&quot;:[&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;2&quot;,&quot;email&quot;:&quot;2&quot;,&quot;order_id&quot;:2,&quot;order_serial&quot;:&quot;2&quot;,&quot;order_time&quot;:1625457046000,&quot;customer_order&quot;:&quot;2&quot;,&quot;c_time&quot;:1625457049000&#125;],&quot;database&quot;:&quot;redtom_dev&quot;,&quot;destination&quot;:&quot;example&quot;,&quot;es&quot;:1625457275000,&quot;groupId&quot;:&quot;g1&quot;,&quot;isDdl&quot;:false,&quot;old&quot;:[&#123;&quot;name&quot;:&quot;1&quot;,&quot;email&quot;:&quot;1&quot;,&quot;order_id&quot;:1,&quot;order_serial&quot;:&quot;1&quot;,&quot;customer_order&quot;:&quot;1&quot;&#125;],&quot;pkNames&quot;:[],&quot;sql&quot;:&quot;&quot;,&quot;table&quot;:&quot;customer&quot;,&quot;ts&quot;:1625457276401,&quot;type&quot;:&quot;UPDATE&quot;&#125;</span><br><span class="line">Affected indexes: customer</span><br></pre></td></tr></table></figure><p>Elastcisearch 效果<br><img src="https://oscimg.oschina.net/oscnet/up-afadff417c35ecb74811967d8e1da10f134.png" width=700 height=400></p><h5 id="删除一条数据"><a href="#删除一条数据" class="headerlink" title="删除一条数据"></a>删除一条数据</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-07-05 11:56:51.524 [pool-3-thread-1] DEBUG c.a.o.canal.client.adapter.es.core.service.ESSyncService - DML: &#123;&quot;data&quot;:[&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;2&quot;,&quot;email&quot;:&quot;2&quot;,&quot;order_id&quot;:2,&quot;order_serial&quot;:&quot;2&quot;,&quot;order_time&quot;:1625457046000,&quot;customer_order&quot;:&quot;2&quot;,&quot;c_time&quot;:1625457049000&#125;],&quot;database&quot;:&quot;redtom_dev&quot;,&quot;destination&quot;:&quot;example&quot;,&quot;es&quot;:1625457411000,&quot;groupId&quot;:&quot;g1&quot;,&quot;isDdl&quot;:false,&quot;old&quot;:null,&quot;pkNames&quot;:[],&quot;sql&quot;:&quot;&quot;,&quot;table&quot;:&quot;customer&quot;,&quot;ts&quot;:1625457411523,&quot;type&quot;:&quot;DELETE&quot;&#125;</span><br><span class="line">Affected indexes: customer</span><br></pre></td></tr></table></figure><p>Elastcisearch 效果<br><img src="https://oscimg.oschina.net/oscnet/up-7f49aeda581a547bf528b55bad6d0af27de.png" width=700 height=400></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href="https://blog.csdn.net/puhaiyang/article/details/100171395">使用canal client-adapter完成mysql到es数据同步教程(包括全量和增量)</a></li><li><a href="https://github.com/alibaba/canal/issues/1514">es 同步问题 #1514 Github issue</a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;首先安装elk&quot;&gt;&lt;a href=&quot;#首先安装elk&quot; class=&quot;headerlink&quot; title=&quot;首先安装elk&quot;&gt;&lt;/a&gt;首先安装elk&lt;/h2&gt;&lt;p&gt;推荐大家到elasic中文社区去下载 👉 &lt;a href=&quot;https://elasticsear</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="elasticsearch" scheme="http://example.com/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>mysql配置binlog</title>
    <link href="http://example.com/wiki/binlog%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/wiki/binlog%E9%85%8D%E7%BD%AE/</id>
    <published>2021-07-05T03:06:36.000Z</published>
    <updated>2021-07-05T03:10:53.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开启binlog"><a href="#开启binlog" class="headerlink" title="开启binlog"></a>开启binlog</h2><p>[mysqld]<br>log-bin=mysql-bin #添加这一行就ok<br>binlog-format=ROW #选择row模式<br>server_id=1 #配置mysql replaction需要定义，不能和canal的slaveId重复  </p><h2 id="查看binlog状态"><a href="#查看binlog状态" class="headerlink" title="查看binlog状态"></a>查看binlog状态</h2><p>mysql&gt; show variables like ‘binlog_format’;</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| binlog_format | ROW   |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure><p>show variables like ‘log_bin’;</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| log_bin       | ON    |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;开启binlog&quot;&gt;&lt;a href=&quot;#开启binlog&quot; class=&quot;headerlink&quot; title=&quot;开启binlog&quot;&gt;&lt;/a&gt;开启binlog&lt;/h2&gt;&lt;p&gt;[mysqld]&lt;br&gt;log-bin=mysql-bin #添加这一行就ok&lt;br&gt;bin</summary>
      
    
    
    
    <category term="DataBase" scheme="http://example.com/categories/DataBase/"/>
    
    <category term="MySQl" scheme="http://example.com/categories/DataBase/MySQl/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>mysql常用命令</title>
    <link href="http://example.com/wiki/mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://example.com/wiki/mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</id>
    <published>2021-07-05T03:06:36.000Z</published>
    <updated>2021-07-05T03:09:20.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="binlog相关命令"><a href="#binlog相关命令" class="headerlink" title="binlog相关命令"></a>binlog相关命令</h2><p>mysql&gt; show variables like ‘binlog_format’;</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| binlog_format | ROW   |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure><p>show variables like ‘log_bin’;</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| log_bin       | ON    |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;binlog相关命令&quot;&gt;&lt;a href=&quot;#binlog相关命令&quot; class=&quot;headerlink&quot; title=&quot;binlog相关命令&quot;&gt;&lt;/a&gt;binlog相关命令&lt;/h2&gt;&lt;p&gt;mysql&amp;gt; show variables like ‘binlog_</summary>
      
    
    
    
    <category term="DataBase" scheme="http://example.com/categories/DataBase/"/>
    
    <category term="MySQl" scheme="http://example.com/categories/DataBase/MySQl/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>flink简单上手</title>
    <link href="http://example.com/wiki/flink%E7%AE%80%E5%8D%95%E4%B8%8A%E6%89%8B/"/>
    <id>http://example.com/wiki/flink%E7%AE%80%E5%8D%95%E4%B8%8A%E6%89%8B/</id>
    <published>2021-07-04T14:23:43.000Z</published>
    <updated>2021-07-05T12:42:59.296Z</updated>
    
    <content type="html"><![CDATA[<h2 id="mac-安装-flink"><a href="#mac-安装-flink" class="headerlink" title="mac 安装 flink"></a>mac 安装 flink</h2><p><b>1、执行 brew install apache-flink 命令</b></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">gaolei:/ gaolei$ brew install apache-flink</span><br><span class="line">Updating Homebrew...</span><br><span class="line">==&gt; Auto-updated Homebrew!  </span><br><span class="line">Updated 1 tap (homebrew/services).</span><br><span class="line">No changes to formulae.</span><br><span class="line"></span><br><span class="line">==&gt; Downloading https://archive.apache.org/dist/flink/flink-1.9.1/flink-1.9.1-bin-scala_2.11.tgz</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">####################################################################### 100.0%</span></span></span><br><span class="line">🍺  /usr/local/Cellar/apache-flink/1.9.1: 166 files, 277MB, built in 15 minutes 29 seconds</span><br></pre></td></tr></table></figure><p><b>2、执行flink启动脚本</b></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/Cellar/apache-flink/1.9.1/libexec/bin</span><br><span class="line">./start-cluster.sh</span><br></pre></td></tr></table></figure><h2 id="WordCount批处理Demo"><a href="#WordCount批处理Demo" class="headerlink" title="WordCount批处理Demo"></a>WordCount批处理Demo</h2><h3 id="创建maven项目，导入依赖"><a href="#创建maven项目，导入依赖" class="headerlink" title="创建maven项目，导入依赖"></a>创建maven项目，导入依赖</h3><p> 注意自己的flink版本 👇👇</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-java --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-java --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="编写批处理程序"><a href="#编写批处理程序" class="headerlink" title="编写批处理程序"></a>编写批处理程序</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">       <span class="comment">// 1、创建执行环境</span></span><br><span class="line">       ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">       <span class="comment">// 2、读取文件数据</span></span><br><span class="line">       String inputPath = <span class="string">&quot;/Users/gaolei/Documents/DemoProjects/flink-start/src/main/resources/hello.txt&quot;</span>;</span><br><span class="line">       DataSource&lt;String&gt; dataSource = env.readTextFile(inputPath);</span><br><span class="line">       <span class="comment">// 对数据集进行处理 按照空格分词展开 转换成（word，1）二元组</span></span><br><span class="line">       AggregateOperator&lt;Tuple2&lt;String, Integer&gt;&gt; result = dataSource.flatMap(<span class="keyword">new</span> MyFlatMapper())</span><br><span class="line">               <span class="comment">// 按照第一个位置 -&gt; word 分组</span></span><br><span class="line">               .groupBy(<span class="number">0</span>)</span><br><span class="line">               .sum(<span class="number">1</span>);</span><br><span class="line">       result.print();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFlatMapper</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// 首先按照空格分词</span></span><br><span class="line">           String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">           <span class="comment">// 遍历所有的word 包装成二元组输出</span></span><br><span class="line">           <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">               collector.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(word, <span class="number">1</span>));</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="准备数据源文件"><a href="#准备数据源文件" class="headerlink" title="准备数据源文件"></a>准备数据源文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hello spark</span><br><span class="line">hello world</span><br><span class="line">hello java</span><br><span class="line">hello flink</span><br><span class="line">how are you</span><br><span class="line">what is your name</span><br></pre></td></tr></table></figure><h3 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(is,1)</span><br><span class="line">(what,1)</span><br><span class="line">(you,1)</span><br><span class="line">(flink,1)</span><br><span class="line">(name,1)</span><br><span class="line">(world,1)</span><br><span class="line">(hello,4)</span><br><span class="line">(your,1)</span><br><span class="line">(are,1)</span><br><span class="line">(java,1)</span><br><span class="line">(how,1)</span><br><span class="line">(spark,1)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;mac-安装-flink&quot;&gt;&lt;a href=&quot;#mac-安装-flink&quot; class=&quot;headerlink&quot; title=&quot;mac 安装 flink&quot;&gt;&lt;/a&gt;mac 安装 flink&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1、执行 brew install apache-fl</summary>
      
    
    
    
    <category term="Apache Flink" scheme="http://example.com/categories/Apache-Flink/"/>
    
    
    <category term="flink" scheme="http://example.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink</title>
    <link href="http://example.com/wiki/flink%E7%AE%80%E4%BB%8B/"/>
    <id>http://example.com/wiki/flink%E7%AE%80%E4%BB%8B/</id>
    <published>2021-07-04T12:45:57.000Z</published>
    <updated>2021-07-05T05:44:30.585Z</updated>
    
    <content type="html"><![CDATA[<img src="https://flink.apache.org/img/flink-header-logo.svg" width=300 height=300><p>官方地址请戳👉 <a href="https://flink.apache.org/">【传送】</a> </p><blockquote><p>Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.  </p></blockquote><p>Apache Flink 是一个框架和分布式处理器引擎，用于对无界和有界数据进行状态计算；  </p><h2 id="Why-Flink"><a href="#Why-Flink" class="headerlink" title="Why Flink"></a>Why Flink</h2><ul><li>流数据更真实地反应了我们的生活方式</li><li>传统的数据架构是基于有限数据集的</li><li>我们的目标<br>1、低延迟 毫秒级响应<br>2、高吞吐 能够处理海量数据 分布式<br>3、结果的准确性和良好的容错性  </li></ul><h2 id="Where-need-Flink"><a href="#Where-need-Flink" class="headerlink" title="Where need Flink"></a>Where need Flink</h2><ul><li>电商和市场营销<br>数据报表、广告投放、业务流程需要</li><li>物联网（IOT）<br>传感器实时数据采集和显示，实时报警，交通运输业</li><li>电信业<br>基站流量调配</li><li>银行和金融业<br>实时结算和通知推送、实时检测异常行为</li></ul><h2 id="传统数据处理架构"><a href="#传统数据处理架构" class="headerlink" title="传统数据处理架构"></a>传统数据处理架构</h2><img src="https://oscimg.oschina.net/oscnet/up-5c77526cb1dbc4696143519dff42c447149.png" width=500 height=300><p>传统的数据处理架构如上👆<br>CRM(用户关系系统)， Order System(订单系统), Web App (用户点击时间)，当用户出发行为之后需要系统作出响应，首先由上层的计算层处理计算逻辑，计算层的逻辑计算依赖下面的存储层，计算层计算完成之后，将响应返回给客户端。<br>这种基于传统数据库方式无法满足高并发场景，数据库的并发量都是很低的。</p><h2 id="分析处理流程"><a href="#分析处理流程" class="headerlink" title="分析处理流程"></a>分析处理流程</h2><img src="https://oscimg.oschina.net/oscnet/up-060fc9ea54c7bfc0e2d5d73b2d674cad5d4.png" width="500" height="300">分析处理流程架构如上👆，数据先有传统的关系数据库，经过提取，清洗过滤等，将数据存放到数据仓库，然后通过一些sql处理，生成数据报表和一些其他的查询。  <ul><li>问题也很明显，实时性太差了，处理流程太长，无法满足毫秒级需求</li><li>数据来源不唯一，能满足海量数据和高并发的需求，但是无法满足实时的需求</li></ul><h2 id="有状态的流式处理"><a href="#有状态的流式处理" class="headerlink" title="有状态的流式处理"></a>有状态的流式处理</h2><img src="https://oscimg.oschina.net/oscnet/up-cdf03c1c17f534673e73968bb4a094aadbc.png" width="500" height="300">把当前做流式计算所需要的数据不存放在数据库中，而是简单粗暴的直接放到本地内存中；<h3 id="内存不稳定？"><a href="#内存不稳定？" class="headerlink" title="内存不稳定？"></a>内存不稳定？</h3><p>周期性的检查点，数据存盘和故障检测；    </p><h2 id="lambda架构"><a href="#lambda架构" class="headerlink" title="lambda架构"></a>lambda架构</h2><p>用两台系统同时保障低延迟和结果准确；<br><img src="https://oscimg.oschina.net/oscnet/up-d33708041d13956206958f26e3b5b209a37.png" width="500" height="300"></p><ul><li>这套架构分成两个流程，上面为批处理流程，数据收集到一定程序，交给批处理器处理，最终产生一个批处理结果</li><li>下面的流程为流式处理流程，保证能快速得到结果</li><li>最终有我们在应用层根据实际问题选择具体的处理结果交给应用程序这种架构有什么缺陷？<br>可能得到的结果是不准确的，我们可以先快速的得到一个实时计算的结果，隔一段时间之后在来看批处理产生的结果。<br>实现两台系统和维护两套系统，成本很大；  </li></ul><h2 id="第三代流式处理架构"><a href="#第三代流式处理架构" class="headerlink" title="第三代流式处理架构"></a>第三代流式处理架构</h2><p>Apache Flink 可以完美解决上面的问题👆<br><img src="https://oscimg.oschina.net/oscnet/up-0cec29eb67e668b76cd1387a0cfe71e47a0.png" width="350" height="350"><br>Strom无法满足海量数据； Sparking Stream 无法满足低延迟；  </p><h3 id="基于事件驱动-（Event-driven）"><a href="#基于事件驱动-（Event-driven）" class="headerlink" title="基于事件驱动 （Event-driven）"></a>基于事件驱动 （Event-driven）</h3><img src="https://oscimg.oschina.net/oscnet/up-cf462b316ee2d27df780fd551ce8ecc72cb.png" width="450" height="330">  <h3 id="处理无界和有界数据"><a href="#处理无界和有界数据" class="headerlink" title="处理无界和有界数据"></a>处理无界和有界数据</h3><p>任何类型的数据都可以形成一种事件流。信用卡交易、传感器测量、机器日志、网站或移动应用程序上的用户交互记录，所有这些数据都形成一种流。<br>数据可以被作为 无界 或者 有界 流来处理。  </p><ul><li><p><b>无界流</b> 有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性。</p></li><li><p><b>有界流&lt;/&gt; 有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理</p></li></ul><img src="https://flink.apache.org/img/bounded-unbounded.png" width="600" height="330" ><p><b>Apache Flink 擅长处理无界和有界数据集</b> 精确的时间控制和状态化使得 Flink 的运行时(runtime)能够运行任何处理无界流的应用。有界流则由一些专为固定大小数据集特殊设计的算法和数据结构进行内部处理，产生了出色的性能。</p><h3 id="其他特点"><a href="#其他特点" class="headerlink" title="其他特点"></a>其他特点</h3><ul><li>支持事件时间（event-time）和处理时间（processing-time）语义</li><li>精确一次的状态一致性保证</li><li>低延迟 每秒处理数百万个事件，毫秒级延迟</li><li>与众多常用的存储系统链接</li><li>高可用，动态扩展，支持7*24全天运行</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p>1、<a href="https://www.bilibili.com/video/BV1qy4y1q728?from=search&seid=13654102476223768024">尚硅谷 2021 Flink Java版</a><br>2、<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/">Apache Flink Documentation</a>  </p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;img src=&quot;https://flink.apache.org/img/flink-header-logo.svg&quot; width=300 height=300&gt;


&lt;p&gt;官方地址请戳👉 &lt;a href=&quot;https://flink.apache.org/&quot;&gt;【传送】&lt;/</summary>
      
    
    
    
    <category term="Apache Flink" scheme="http://example.com/categories/Apache-Flink/"/>
    
    
    <category term="flink" scheme="http://example.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>拥塞避免</title>
    <link href="http://example.com/wiki/%E6%8B%A5%E5%A1%9E%E9%81%BF%E5%85%8D/"/>
    <id>http://example.com/wiki/%E6%8B%A5%E5%A1%9E%E9%81%BF%E5%85%8D/</id>
    <published>2021-07-04T08:46:13.000Z</published>
    <updated>2021-07-04T08:47:38.792Z</updated>
    
    <content type="html"><![CDATA[<h1 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h1><p>拥塞控制的慢启动是以指数方式快速的通过试探来扩大拥塞窗口的，但是一旦发生网络丢包，则肯定是很多报文段都会都是，因为窗口时称被增长的；为了解决这种问题，需要引入– 拥塞避免</p><h2 id="什么是拥塞避免"><a href="#什么是拥塞避免" class="headerlink" title="什么是拥塞避免"></a>什么是拥塞避免</h2><p>拥塞避免为了解决慢启动下，当拥塞窗口超出网络带宽时发生的大量丢包问题，它提出一个「慢启动阈值」的概念，当拥塞窗口到达这个阈值之后，不在以指数方式增长，而选择涨幅比较缓慢的「线性增长」，计算方式：</p><blockquote><p>w cwnd += SMSS*SMSS/cwnd</p></blockquote><img src="https://oscimg.oschina.net/oscnet/up-e56d8072b2a74fa9b18ff6ca2d605405d2f.png" width=760 height=360><p>当拥塞窗口在线性增长时发生丢包，将慢启动阈值设置为当前窗口的一半，慢启动窗口恢复初始窗口（init wnd）；</p><blockquote><p>i 拥塞避免和慢启动是结合使用的，当发生网络丢包是，拥塞控制采用快速重传和快速启动来解决丢包问题！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;拥塞避免&quot;&gt;&lt;a href=&quot;#拥塞避免&quot; class=&quot;headerlink&quot; title=&quot;拥塞避免&quot;&gt;&lt;/a&gt;拥塞避免&lt;/h1&gt;&lt;p&gt;拥塞控制的慢启动是以指数方式快速的通过试探来扩大拥塞窗口的，但是一旦发生网络丢包，则肯定是很多报文段都会都是，因为窗口时称被</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP-四次挥手/断开连接</title>
    <link href="http://example.com/wiki/TCP-%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B-%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5/"/>
    <id>http://example.com/wiki/TCP-%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B-%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5/</id>
    <published>2021-07-04T08:34:11.000Z</published>
    <updated>2021-07-04T08:47:31.738Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TCP断开连接"><a href="#TCP断开连接" class="headerlink" title="TCP断开连接"></a>TCP断开连接</h1><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><img src="https://oscimg.oschina.net/oscnet/up-8d9a6b405e874bc02b91e453bd277c46d46.png" width=450 height=550><ul><li>开始客户端和服务端都是处理【established】状态</li><li>客户端发送「FIN」报文之后，进入FIN-WAIT-1状态</li><li>服务端收到客户端的FIN之后，恢复一个ACK，同时进入CLOSE_WAIT状态</li><li>客户端接收到ACK之后，进入到FIN-WAIT-2状态</li><li>服务端接着发送FIN报文，同时进入LAST-ACK状态</li><li>客户端接收到服务端的FIN报文之后，发送ACK报文，并进入TIME_WAIT状态</li><li>客户端在经历2个MSL时间之后，进入CLOSE状态</li><li>服务端接收到客户端的ACK之后，进入CLOSE状态</li></ul><blockquote><p>i 并不是所有的四次挥手都是上述流程，当客户端和服务端同时发送关闭连接的请求如下👇：</p></blockquote><img src="https://oscimg.oschina.net/oscnet/up-d859884b062bda56a946ae9e3c0c148235b.png" width=450 height=550><p>可以看到双方都主动发起断开请求所以各自都是主动发起方，状态会从 FIN_WAIT_1 都进入到 CLOSING 这个过度状态然后再到 TIME_WAIT。</p><blockquote><p>i 挥手一定需要四次吗？</p></blockquote><p>假设 client 已经没有数据发送给 server 了，所以它发送 FIN 给 server 表明自己数据发完了，不再发了，如果这时候 server 还是有数据要发送给 client 那么它就是先回复 ack ，然后继续发送数据。<br>等 server 数据发送完了之后再向 client 发送 FIN 表明它也发完了，然后等 client 的 ACK 这种情况下就会有四次挥手。<br>那么假设 client 发送 FIN 给 server 的时候 server 也没数据给 client，那么 server 就可以将 ACK 和它的 FIN 一起发给client ，然后等待 client 的 ACK，这样不就三次挥手了？</p><blockquote><p>i 为什么要有 TIME_WAIT?</p></blockquote><p>断开连接发起方在接受到接受方的 FIN 并回复 ACK 之后并没有直接进入 CLOSED 状态，而是进行了一波等待，等待时间为 2MSL。MSL 是 Maximum Segment Lifetime，即报文最长生存时间，RFC 793 定义的 MSL 时间是 2 分钟，Linux 实际实现是 30s，那么 2MSL 是一分钟。</p><blockquote><p>w <font color=red >那么为什么要等 2MSL 呢？</font></p></blockquote><ul><li>就是怕被动关闭方没有收到最后的 ACK，如果被动方由于网络原因没有到，那么它会再次发送 FIN， 此时如果主动关闭方已经 CLOSED 那就傻了，因此等一会儿。</li><li>假设立马断开连接，但是又重用了这个连接，就是五元组完全一致，并且序号还在合适的范围内，虽然概率很低但理论上也有可能，那么新的连接会被已关闭连接链路上的一些残留数据干扰，因此给予一定的时间来处理一些残留数据。</li></ul><blockquote><p>i 等待 2MSL 会产生什么问题？</p></blockquote><p>如果服务器主动关闭大量的连接，那么会出现大量的资源占用，需要等到 2MSL 才会释放资源。<br>如果是客户端主动关闭大量的连接，那么在 2MSL 里面那些端口都是被占用的，端口只有 65535 个，如果端口耗尽了就无法发起送的连接了，不过我觉得这个概率很低，这么多端口你这是要建立多少个连接？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;TCP断开连接&quot;&gt;&lt;a href=&quot;#TCP断开连接&quot; class=&quot;headerlink&quot; title=&quot;TCP断开连接&quot;&gt;&lt;/a&gt;TCP断开连接&lt;/h1&gt;&lt;h2 id=&quot;四次挥手&quot;&gt;&lt;a href=&quot;#四次挥手&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>快速重传/快速恢复</title>
    <link href="http://example.com/wiki/%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0-%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D/"/>
    <id>http://example.com/wiki/%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0-%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D/</id>
    <published>2021-07-04T08:33:35.000Z</published>
    <updated>2021-07-04T08:47:36.949Z</updated>
    
    <content type="html"><![CDATA[<h1 id="快速重传和快速恢复"><a href="#快速重传和快速恢复" class="headerlink" title="快速重传和快速恢复"></a>快速重传和快速恢复</h1><h2 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h2><blockquote><p>d 为何会接收到以个失序数据段？ </p></blockquote><ul><li>若报文丢失，将会产生连续的失序ACK段 </li><li>若网络路径与设备导致数据段失序，将会产生少量的失序ACK段</li><li>若报文重复，将会产生少量的失序ACK段</li></ul><img src="https://oscimg.oschina.net/oscnet/up-eaadaebd682089bdd3919de4f0d232749dc.png" width=450 height= 520><ul><li>当发送端发送pkt0是正常的，由于滑动窗口为满，发送方可以继续发送pkt1，pkt2；</li><li>加入pkt1发生了丢包，虽然pkt2接收端接收成功了，但是没有pkt1的数据段，接收端还是发送ACK1的确认报文；</li><li>在没有「快速重传」的情况下，发送端需要等到RTO之后，才可以重新发送pkt1</li><li>重传成功之后，接收端其实收到了pkt2之前的所有数据段，所以发送ACK3的确认报文<blockquote><p>w 这种需要等待RTO才可以重传的方式效率是比较低的，因此需要快速重传来进行优化；</p></blockquote></li></ul><h2 id="快速重传和累积确认"><a href="#快速重传和累积确认" class="headerlink" title="快速重传和累积确认"></a>快速重传和累积确认</h2><img src="https://oscimg.oschina.net/oscnet/up-9da669c35316aafb318674d3364ea07d72d.png" width=450 height=520><p>当发送方连续发送pkt3，pkt4，pkt5，pkt6四个数据端，但是pkt5在网络中丢包了，那后面发送的pkt6，pkt7，pkt8的确认报文都返回ACK5，希望发送方吃昂传pkt5的数据段；这个时候，发送方收到连续3个相同的确认报文，便立即重新发送pkt5的数据段；</p><blockquote><p>i 接收方:</p></blockquote><ul><li>当接收到一个失序数据段时，立刻发送它所期待的缺口 ACK 序列号</li><li>当接收到填充失序缺口的数据段时，立刻发 送它所期待的下一个 ACK 序列号</li></ul><blockquote><p>i 发送方</p></blockquote><ul><li>当接收到3个重复的失序 ACK 段(4个相同的失序ACK段)时，不再等待重传定时器的触发，立刻基于快速重传机制重发报文段</li></ul><p>当pkt5重新发送并被接收端接收之后，接收端发送ACK9的确认报文，而不是再分别发送ACK6，ACK7，ACK8，这个称谓「 <strong><font color=red>累计确认</font></strong> 」。</p><h2 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h2><blockquote><p>i 快速重传下一定要进入慢启动吗?</p></blockquote><p>接受端收到重复ACK，意味着网络仍在流动，而如果要重新进入慢启动，会导致网络突然减少数据流，拥塞窗口恢复初始窗口，所以，「<strong>在快速恢复下发生丢包的场景下</strong>」，应该使用快速恢复，简单的讲，就是将慢启动阈值设置成当前拥塞窗口的一半，而拥塞窗口也适当放低，而不是一下字恢复到初始窗口大小；</p><img src="https://oscimg.oschina.net/oscnet/up-4a7f76cb315a13d1d905f2bfb3a376db087.png" ><p>快速恢复的流程如上图👆所示！</p><blockquote><p>w 快速恢复的具体操作：</p></blockquote><ul><li>将 ssthresh 设置为当前拥塞窗口 cwnd 的一半，设当前 cwnd 为 ssthresh 加上 3*MSS</li><li>每收到一个重复 ACK，cwnd 增加 1 个 MSS</li><li>当新数据 ACK 到达后，设置 cwnd 为 ssthresh</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;快速重传和快速恢复&quot;&gt;&lt;a href=&quot;#快速重传和快速恢复&quot; class=&quot;headerlink&quot; title=&quot;快速重传和快速恢复&quot;&gt;&lt;/a&gt;快速重传和快速恢复&lt;/h1&gt;&lt;h2 id=&quot;快速重传&quot;&gt;&lt;a href=&quot;#快速重传&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP-拥塞控制之慢启动</title>
    <link href="http://example.com/wiki/TCP-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8B%E6%85%A2%E5%90%AF%E5%8A%A8/"/>
    <id>http://example.com/wiki/TCP-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8B%E6%85%A2%E5%90%AF%E5%8A%A8/</id>
    <published>2021-07-04T08:33:19.000Z</published>
    <updated>2021-07-04T08:44:47.627Z</updated>
    
    <content type="html"><![CDATA[<p>由于TCP是面向字节流的传输协议，可以发送不定长的字节流数据，TCP连接发送数据时会“先天性”尝试占用整个带宽，而当所有的TCP连接都尝试占用网络带宽时，就会造成网络的堵塞，而TCP慢启动算法则是为了解决这一场景；</p><h2 id="全局思考"><a href="#全局思考" class="headerlink" title="全局思考"></a>全局思考</h2><img src="https://oscimg.oschina.net/oscnet/up-b70475e1aadd0776c54efdd5ecf26ef2606.png" width=700 height=400><p>拥塞控制要面向整体思考，如上👆网络拓扑图，当左边的网络节点通过路由交换设备向右边的设备传输报文的时候，中间的某一链路的带宽肯定是一定的，这里假设1000M带宽，当左边R1以700Mb/s的速度向链路中发送数据，同时R2以600Mb/s的速率发送报文，那势必会有300Mb的数据报丢失；「路由交换设备基于存储转发来实现报文的发送」大量报文都是时，路由设备的缓冲队列肯定是慢的，这也会造成某些数据报在网络链路中停留时间过长，从而导致TCP通讯变慢，甚至网络瘫痪；</p><p>理想的情况下，当链路带宽占满以后，链路以最大带宽传输数据，当然显示中是不可能的，当发生轻度拥塞时，链路的吞吐量就开始下降了，发展到严重阻塞时，链路的吞吐量会严重地下降，甚至瘫痪；</p><p>那么，慢启动是如何发挥作用的呢？</p><h2 id="拥塞窗口"><a href="#拥塞窗口" class="headerlink" title="拥塞窗口"></a>拥塞窗口</h2><blockquote><p>s 拥塞窗口cwnd(congestion window)</p></blockquote><ul><li>通告窗口rwnd(receiver‘s advertised window) <blockquote><p>其实就是RCV.WND，标志在TCP首部的Window字段！</p></blockquote></li><li>发送窗口swnd = min(cwnd，rwnd)<blockquote><p>前面学习滑动窗口的时候提到发送窗口大致等于接受窗口，当引入拥塞窗口时，发送窗口就是拥塞窗口和对方接受窗口的最小值</p></blockquote></li></ul><img src="https://oscimg.oschina.net/oscnet/up-4fffa8af1fb99c1ce534085f112fa9f065c.png" width=360 height=360><blockquote><p>i 每收到一个ACK，cwnd扩充一倍</p></blockquote><p>慢启动的窗口大小如何设置呢？<br>如上所示，起初拥塞窗口设置成1个报文段大小，当发送端发送一个报文段并且没有发生丢包时，调整拥塞窗口为2个报文段大小，如果还没有发生丢包，一次类推，知道发生丢包停止；发送窗口以「指数」的方式扩大；慢启动是无法确知网络拥塞程度的情况下，以试探性地方式快速扩大拥塞窗口；</p><h2 id="慢启动初始窗口"><a href="#慢启动初始窗口" class="headerlink" title="慢启动初始窗口"></a>慢启动初始窗口</h2><p>慢启动的拥塞窗口真的就如上面所说的以一个报文段大小作为初始值吗？  </p><img src="https://oscimg.oschina.net/oscnet/up-e632e6592fd276be90e5cf65a8365b3ddfb.png" width=360 height=360>  <blockquote><p>w 慢启动初始窗口 IW(Initial Window)的变迁</p></blockquote><ul><li>1 SMSS:RFC2001(1997)</li><li>2 - 4 SMSS:RFC2414(1998)<blockquote><p>IW = min (4<em>SMSS, max (2</em>SMSS, 4380 bytes))</p></blockquote></li><li>10 SMSS:RFC6928(2013)<blockquote><p>IW = min (10<em>MSS, max (2</em>MSS, 14600))</p></blockquote></li></ul><blockquote><p>w 其实在实际情况下，互联网中的网页都在10个mss左右，如果还是从1个mss开始，则会浪费3个RTT的时间；  </p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于TCP是面向字节流的传输协议，可以发送不定长的字节流数据，TCP连接发送数据时会“先天性”尝试占用整个带宽，而当所有的TCP连接都尝试占用网络带宽时，就会造成网络的堵塞，而TCP慢启动算法则是为了解决这一场景；&lt;/p&gt;
&lt;h2 id=&quot;全局思考&quot;&gt;&lt;a href=&quot;#全</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP-如何减少小报文提升网络效率</title>
    <link href="http://example.com/wiki/TCP-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E5%B0%8F%E6%8A%A5%E6%96%87%E6%8F%90%E5%8D%87%E7%BD%91%E7%BB%9C%E6%95%88%E7%8E%87/"/>
    <id>http://example.com/wiki/TCP-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E5%B0%8F%E6%8A%A5%E6%96%87%E6%8F%90%E5%8D%87%E7%BD%91%E7%BB%9C%E6%95%88%E7%8E%87/</id>
    <published>2021-07-04T08:32:55.000Z</published>
    <updated>2021-07-04T08:47:34.548Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何减少小报文提升网络效率"><a href="#如何减少小报文提升网络效率" class="headerlink" title="如何减少小报文提升网络效率"></a>如何减少小报文提升网络效率</h1><p>每一个TCP报文段都包含20字节的IP头部和20字节的TCP首部，如果报文段的数据部分很少的话，网络效率会很差；</p><h2 id="SWS-Silly-Window-syndrome-糊涂窗口综合症"><a href="#SWS-Silly-Window-syndrome-糊涂窗口综合症" class="headerlink" title="SWS(Silly Window syndrome) 糊涂窗口综合症"></a>SWS(Silly Window syndrome) 糊涂窗口综合症</h2><image src="https://oscimg.oschina.net/oscnet/up-777275434842bda3be80da2687c4556ee3b.png" width=600 height=450 ><p>如上图👆所示场景，在之前的滑动窗口已经了解过，随着服务端处理连接数据能力越来越低，服务端的可用窗口不断压缩，最终导致窗口关闭；</p><h3 id="SWS-避免算法"><a href="#SWS-避免算法" class="headerlink" title="SWS 避免算法"></a>SWS 避免算法</h3><p>SWS 避免算法对发送方和接收方都做客</p><ul><li>接收方<blockquote><p>i David D Clark 算法:窗口边界移动值小于 min(MSS, 缓存/2)时，<br>通知窗口为 0</p></blockquote></li><li>发送方<blockquote><p>w Nagle 算法:<br>1、TCP_NODELAY 用于关闭 Nagle 算法<br>2、没有已发送未确认报文段时，立刻发送数据<br>3、存在未确认报文段时，直到:1-没有已发送未确认报文段，或者 2-数据长度达到MSS时再发送</p></blockquote></li></ul><h2 id="TCP-delayed-acknowledgment-延迟确认"><a href="#TCP-delayed-acknowledgment-延迟确认" class="headerlink" title="TCP delayed acknowledgment 延迟确认"></a>TCP delayed acknowledgment 延迟确认</h2><p>实际情况下，没有携带任何数据的ACK报文也会造成网络效率低下的，因为确认报文也包含40字节的头部信息，但仅仅是为了传输ACK=1这样的信息，为了解决这种情况，TCP有一种机制，叫做延迟确认，如下👇：</p><ul><li>当有响应数据要发送时,ack会随着响应数据立即发送给对方.</li><li>如果没有响应数据,ack的发送将会有一个延迟,以等待看是否有响应数据可以一起发送</li><li>如果在等待发送ack期间,对方的第二个数据段又到达了,这时要立即发送ack</li></ul><h3 id="那个延迟的时间如何设置呢？"><a href="#那个延迟的时间如何设置呢？" class="headerlink" title="那个延迟的时间如何设置呢？"></a>那个延迟的时间如何设置呢？</h3><image src="https://oscimg.oschina.net/oscnet/up-5933d7b1310c191603f366eb55669a7cdc8.png" width=400 height=250><p>上面👆是Linux操作系统对于TCP延时的定义。</p><p>HZ是什呢？其实那是和操作系统的时钟相关的，具体的操作系统间各有差别；<br>如何查看Linux操作系统下的HZ如何设置呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /boot/config- `-uname -r` | grep &#x27;^GONFIG_HZ=&#x27;</span><br></pre></td></tr></table></figure><h2 id="TCP-CORK"><a href="#TCP-CORK" class="headerlink" title="TCP_CORK"></a>TCP_CORK</h2><blockquote><p>sendfile 零拷贝技术</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;如何减少小报文提升网络效率&quot;&gt;&lt;a href=&quot;#如何减少小报文提升网络效率&quot; class=&quot;headerlink&quot; title=&quot;如何减少小报文提升网络效率&quot;&gt;&lt;/a&gt;如何减少小报文提升网络效率&lt;/h1&gt;&lt;p&gt;每一个TCP报文段都包含20字节的IP头部和20字节</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP-滑动窗口</title>
    <link href="http://example.com/wiki/TCP-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"/>
    <id>http://example.com/wiki/TCP-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/</id>
    <published>2021-07-04T08:32:40.000Z</published>
    <updated>2021-07-04T08:43:48.561Z</updated>
    
    <content type="html"><![CDATA[<h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><blockquote><p>i 之前学习了PAR方式的TCP超时和重传，其实在考虑发送方发送数据报的同时，也应该考虑接收方对于数据的处理能力，由此引出本次学习的主题 – 滑动窗口</p></blockquote><h2 id="发送端窗口"><a href="#发送端窗口" class="headerlink" title="发送端窗口"></a>发送端窗口</h2><p>滑动窗口按照传输数据方向分为两种，发送端窗口和接收端窗口；下面先看一下发送端窗口👇：</p><image src="https://oscimg.oschina.net/oscnet/up-13e77c53892b884d334614e4fa9550a1113.png"><p>上图分为四个部分：</p><ol><li>已发送并收到 Ack 确认的数据:1-31 字节</li><li>已发送未收到 Ack 确认的数据:32-45 字节</li><li>未发送但总大小在接收方处理范围内:46-51 字节</li><li>未发送但总大小超出接收方处理范围:52-字节</li></ol><h3 id="可用窗口和发送窗口"><a href="#可用窗口和发送窗口" class="headerlink" title="可用窗口和发送窗口"></a>可用窗口和发送窗口</h3><image src="https://oscimg.oschina.net/oscnet/up-b8bb072922232fe6d62aec3520647d869fe.png"> <p>如上图这里可以引出两个概念：「可用窗口」和「发送窗口」</p><blockquote><p>s 【 <strong>可用窗口</strong> 】： 就是上图中的第三部分，属于还未发送，但是在接收端可以处理范围内的部分；<br>【 <strong>发送窗口</strong> 】： 就是发送端可以发送的最大报文大小，如上图中的第二部分+第三部分合成发送窗口；</p></blockquote><h3 id="可用窗口耗尽"><a href="#可用窗口耗尽" class="headerlink" title="可用窗口耗尽"></a>可用窗口耗尽</h3><image src="https://oscimg.oschina.net/oscnet/up-333b88e14f6fd5833fd92a9ab45894e60dd.png"> <p>可用窗口会在一个短暂的停留，当处于未发送并且接受端可以接受范围内的数据传输完成之后，可用窗口耗尽；<br>当然上面仅仅说的一瞬时的状态，这个状态下，已经发送的报文段还没有确认，并且发送窗口大小没有发生变化，此时发送窗口达到最大状态；</p><h3 id="窗口移动"><a href="#窗口移动" class="headerlink" title="窗口移动"></a>窗口移动</h3><image src="https://oscimg.oschina.net/oscnet/up-4436cdb5c6720e3e4a262ec1cad64660a77.png">  <p>如果在发送窗口中已经发送的报文段已经得到接受端确认之后，那部分数据就会被移除发送窗口，在发送窗口大小不发生变化的情况下，发送窗口向右➡️移动5个字节，因为左边已经发送的5个字节得到确认之后，被移除发送窗口；</p><h3 id="可用窗口如何计算"><a href="#可用窗口如何计算" class="headerlink" title="可用窗口如何计算"></a>可用窗口如何计算</h3><image src="https://oscimg.oschina.net/oscnet/up-76f97fc92f6940c7197ff9fcad3c187fd98.png"><p>再次引出三个概念：</p><ul><li>SND.WND<blockquote><p>i SND 指的是发送端，WND指的是window，也就是发送端窗口的意思</p></blockquote></li><li>SND.UNA<blockquote><p>i UNA 就是un ACK的意思，指的是已经发送但是没有没有确认 它指向窗口的第一个字节处</p></blockquote></li><li>SND.NXT<blockquote><p>i NXT 是next的位置，是发送方接下来要发送的位置，它指向可用窗口的第一个字节处</p></blockquote></li></ul><p><strong>那就很容易得出可用窗口的大小了，计算公式如下：</strong></p><blockquote><p>i Usable Window Size = SND.UNA + SND.WND - SND.NXT </p></blockquote><h2 id="接收端窗口"><a href="#接收端窗口" class="headerlink" title="接收端窗口"></a>接收端窗口</h2><p>上面介绍了发送端窗口的一些概念，下面👇是接收端窗口的学习：</p><image src="https://oscimg.oschina.net/oscnet/up-0313775eaecc790ad26b44c3daa17ced593.png"><ol><li>已经接收并且已经确认 :28-31 字节</li><li>还未接收并且接收端可以接受:32-51 字节</li><li>还未接收并且超出接收处理能力:51-57 字节</li></ol><p>这里引出两个概念：</p><ul><li>RCV.WND<blockquote><p>i RCV是接收端的意思，WND是接受端窗口的大小</p></blockquote></li><li>RCV.NXT<blockquote><p>i NXT表示的是接受端接收窗口的开始位置，也就是接收方接下来处理的第一个字节；</p></blockquote></li></ul><p>RCV.WND的大小接受端的内存以及缓冲区大小有关，在某种意义上说，接受端的窗口大小和发送端大小大致相同；<br>接受端可接收的数据能力可以通过TCP首部的Window字段设置，但是接受端的处理能力是可能随时变化的，所以接受端和服务端的窗口大小大致是一样的；</p><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>下面👇根据一个例子来阐述流量控制，模拟一个GET请求，客户端向服务端请求一个260字节的文件，大致流程如下，比较繁琐：</p><image src="https://oscimg.oschina.net/oscnet/up-08e7b2cd9ee3ddaa44bca900a1824e08b09.png" width=900 height=480> <blockquote><p>s 这里假设MSS和窗口的大小不发生变化，同时客户端和发送端状态如下：<br>【 客户端 】： 发送窗口默认360字节 接收窗口设定200字节<br>【 服务端 】： 发送窗口设定200字节 接收窗口设定360字节</p></blockquote><p>Step1： 客户端发送140字节的数据到服务端</p><blockquote><p>i 【客户端】发送140字节，【SND.NXT】从1-&gt;141 </p></blockquote><blockquote><p>w 【服务端】状态不变，等待接收客户端传输的140字节</p></blockquote><p>Step2: 服务端接收140字节，发送80字节响应以及ACK</p><blockquote><p>i 【 客户端 】发送140字节之后等待【 服务端 】的ACK</p></blockquote><blockquote><p>w【 服务端 】可用窗口右移，【RCV.NXT】从1-&gt;141<br>【 服务端 】发送80字节数据，【SND.NXT】从241-&gt;321</p></blockquote><p>Step3: 客户端接收响应ACK，并且发送ACK </p><blockquote><p>i 【 客户端 】发出的140字节得到确认，【SND.UNA】右移140字节<br>【 客户端 】接收80字节数据，【RCV.NXT】右移80字节，从241-&gt;321</p></blockquote><p>Step4: 服务端发送一个280字节的文件，但是280字节超出了客户端的接收窗口，所以客户端分成两部分传输，先传输120字节；</p><blockquote><p>w 【 服务端 】发送120字节，【SND.NXT】向右移动120字节，从321-&gt;441</p></blockquote><p>Step5: 客户端接收文件第一部分，并发送ACK</p><blockquote><p>i 【 客户端 】接收120字节，【RCV.NXT】从321-&gt;441</p></blockquote><p>Step6：服务端接收到第二步80字节的ACK</p><blockquote><p>w [ 服务器 ] 80字节得到ACK 【SND.UNA】从241-&gt;321</p></blockquote><p>Step7: 服务端接收到第4步的确认</p><blockquote><p>w 【 服务端 】之前发送文件第一部分的120字节得到确认，【SND.UNA】右移动120，从321-&gt;441</p></blockquote><p>Step8: 服务端发送文件第二部分的160字节</p><blockquote><p>w 【 服务端 】： 发送160字节，【SND.NXT】向右移动160字节，从441-&gt;601</p></blockquote><p>Step9: 客户端接收到文件第二部分160字节，同时发送ACK</p><blockquote><p>i 【 客户端 】接收160字节，【RCV.NXT】向右移动160字节，从441-&gt;601</p></blockquote><p>Step10: 服务端收到文件第二部分的ACK</p><blockquote><p>w 【 服务端 】发送的160字节得到确认，【SND.UNA】向右一定160字节，从441-&gt;601；至此客户端收到服务端发送的完整的文件；</p></blockquote><p>上面通过表格列举服务端和客户端每个状态在每个步骤的状态，如果不是很好理解，可以看如下示意图辅助理解：</p><h3 id="客户端交互流程"><a href="#客户端交互流程" class="headerlink" title="客户端交互流程"></a>客户端交互流程</h3><image src="https://oscimg.oschina.net/oscnet/up-6ee487f0677efac1a822207f45fc0a2b842.png" width=500 ><h3 id="服务端交互流程"><a href="#服务端交互流程" class="headerlink" title="服务端交互流程"></a>服务端交互流程</h3><image src="https://oscimg.oschina.net/oscnet/up-4a0095fb6e7a82a708e4df96dfdacd956aa.png" width="500"> <p>上面👆是模拟一个GET请求，服务端发送一个280字节的文件给到客户端，客户端的接收窗口是200字节场景加，客户端和服务端的数据传输与交互流程，通过这个流程来学习滑动窗口的移动状态和流量控制的大致流程；</p><h2 id="滑动窗口与操作系统缓冲区"><a href="#滑动窗口与操作系统缓冲区" class="headerlink" title="滑动窗口与操作系统缓冲区"></a>滑动窗口与操作系统缓冲区</h2><p>上面👆讲述的时候，都是假设窗口大小是不变的，而实际上，发送端和接受端的滑动窗口的字节数都吃存储在操作系统缓冲区的，操作系统的缓冲区受操作系统控制，当应用进程增加是，每个进程分配的内存减少，缓冲区减少，分配给每个连接的窗口就会压缩。**<font color="red">而且滑动窗口的大小也受应用进程读取缓冲区数据速度有关</font>**；</p><image src="https://oscimg.oschina.net/oscnet/up-3839118daafc840e059fa6f82d283bef7a9.png" width="500">   <h3 id="应用进程读取缓冲区数据不及时造成窗口收缩"><a href="#应用进程读取缓冲区数据不及时造成窗口收缩" class="headerlink" title="应用进程读取缓冲区数据不及时造成窗口收缩"></a>应用进程读取缓冲区数据不及时造成窗口收缩</h3><p>step1: 客户端发送140字节</p><blockquote><p>i 客户端发送到140字节之后，可用窗口收缩到220字节，发送窗口不变</p></blockquote><p>Step2: 服务端接收140字节 但是应用进程仅仅读取40字节</p><blockquote><p>w 服务端应用进程仅仅读取40字节，仍有100字节占用缓冲区大小，导致接受窗口收缩，服务端发送ACK报文时，在首部Window带上接收窗口的大小260</p></blockquote><p>Step3: 客户端收到确认报文之后，发送窗口收缩到260</p><p>Step4: 客户端继续发送180字节数据</p><blockquote><p>i 客户端发送180字节之后，可用窗口变成80字节</p></blockquote><p>Step5: 服务端接收到180字节</p><blockquote><p>w 假设应用程序仍然不读取这180字节，最终也导致服务端接收窗口再次收缩180字节，仅剩下80字节，在发送确认报文时，设置首部window=80</p></blockquote><p>Step6: 客户端收到80字节的窗口时，调整发送窗口大小为80字节，可用窗口也是80字节</p><p>Step7: 客户端仍然发送80字节到服务端，此时可用窗口为空</p><p>Step8: 服务端应用进程继续不读区这80字节的缓冲区数据，最终导致服务端接收窗口大小为0，不能再接收任何数据，同时发送ACK报文；</p><p>Step9：客户端收到确认报文之后，调整发送窗口大小为0，这个状态叫做「 <strong>窗口关闭</strong> 」</p><h3 id="窗口收缩导致的丢包"><a href="#窗口收缩导致的丢包" class="headerlink" title="窗口收缩导致的丢包"></a>窗口收缩导致的丢包</h3><image src="https://oscimg.oschina.net/oscnet/up-174e19d4d8de9757707034b8271cb3c69a7.png" width="530"><p>Step1：客户端服务端开始的窗口大小都是360字节，客户端发送140字节数据</p><blockquote><p>i 客户端发送140字节之后，可用窗口变成220字节</p></blockquote><p>Step2：服务端应用进程骤增，进程缓存区平均分配，造成服务端接收窗口减少，从360变成240字节；</p><blockquote><p>w 假设接收了140字节之后，应用进程没有读取，那个可用窗口进一步压缩，变成100字节；</p></blockquote><p>Step3：假设同一个连接在没有收到服务端确认之后，又发送了180个字节的数据（Retramission）</p><blockquote><p>i 先发送了140字节，后发送了180字节，都没有得到确认，客户端可用窗口大小变成40字节</p></blockquote><p>Step4：服务端收到上面👆第三步发送的180字节的数据，但是接受窗口的大小只有100字节，所以不能接收</p><blockquote><p>w 服务端拒绝接收180字节</p></blockquote><p>Step5：此时客户端才收到之前140字节的确认报文，才知道接收窗口发生了变化</p><blockquote><p>i 客户端由于没有收到180字节的确认，加入客户端正在准备发送180字节数据，得到接受端的窗口大小是100字节之后，须强制将右侧窗口向左收缩80字节；</p></blockquote><h2 id="窗口关闭"><a href="#窗口关闭" class="headerlink" title="窗口关闭"></a>窗口关闭</h2><p>这个例子和上面的例子都发生了「 <strong><font color="red">窗口关闭</font></strong> 」</p><blockquote><p>s 窗口关闭： 发送端的发送窗口变成0的状态；</p></blockquote><p>上面讲的两种情况一般不会发生的，因为操作系统不会既收缩窗口，同时减少连接缓存；而是一般先使用窗口收缩策略，之后在压缩缓冲区的方式来规避以上问题；<br>发生窗口关闭之后，发送端不会被动的等待服务端的通知，而是会采用定时嗅探的方式去查看服务端接收窗口是否开放；</p><h2 id="Linux中对TCP缓冲区的调整方式"><a href="#Linux中对TCP缓冲区的调整方式" class="headerlink" title="Linux中对TCP缓冲区的调整方式"></a>Linux中对TCP缓冲区的调整方式</h2><ul><li><p>net.ipv4.tcp_rmem = 4096 87380 6291456</p><blockquote><p>读缓存最小值、默认值、最大值，单位字节，覆盖 net.core.rmem_max</p></blockquote></li><li><p>net.ipv4.tcp_wmem = 4096 16384 4194304</p><blockquote><p>写缓存最小值、默认值、最大值，单位字节，覆盖net.core.wmem_max</p></blockquote></li><li><p>net.ipv4.tcp_mem = 1541646 2055528 3083292</p><blockquote><p>系统无内存压力、启动压力模式阀值、最大值，单位为页的数量</p></blockquote></li><li><p>net.ipv4.tcp_moderate_rcvbuf = 1 </p><blockquote><p>开启自动调整缓存模式</p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;滑动窗口&quot;&gt;&lt;a href=&quot;#滑动窗口&quot; class=&quot;headerlink&quot; title=&quot;滑动窗口&quot;&gt;&lt;/a&gt;滑动窗口&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;i 之前学习了PAR方式的TCP超时和重传，其实在考虑发送方发送数据报的同时，也应该考虑接收方对于</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP-RTO重传计数器的计算</title>
    <link href="http://example.com/wiki/TCP-RTO%E9%87%8D%E4%BC%A0%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E8%AE%A1%E7%AE%97/"/>
    <id>http://example.com/wiki/TCP-RTO%E9%87%8D%E4%BC%A0%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E8%AE%A1%E7%AE%97/</id>
    <published>2021-07-04T08:32:27.000Z</published>
    <updated>2021-07-04T08:43:21.073Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>i 之前的文章已经介绍了TCP超时重传的过程中使用了定时器的策略，当定时器规定时间内未收到确认报文之后，就会触发报文的重传，同时定时器复位；那么定时器超时时间（RTO Retramission Timeout）是如何计算的呢？</p></blockquote><h2 id="什么是RTT？"><a href="#什么是RTT？" class="headerlink" title="什么是RTT？"></a>什么是RTT？</h2><p>了解RTO如何计算之前，首先明确一个概念「 <strong>RTT</strong> 」；</p><image src="https://oscimg.oschina.net/oscnet/up-9b45623a3b0652d842ffa3eecea13e92183.png" width=550 height=400>   <p>如上图所示，从client发送第一个「SYN」报文，到Server接受到报文，并且返回「SYN ACK」报文之后，client接受到Server的「ACK」报文之后，client所经历的时间，叫做1个RTT时间；</p><h2 id="如何在重传下有效测量RTT？"><a href="#如何在重传下有效测量RTT？" class="headerlink" title="如何在重传下有效测量RTT？"></a>如何在重传下有效测量RTT？</h2><p><img src="https://oscimg.oschina.net/oscnet/up-6c558bfea1825bf5d3b2da74e087cdde43a.png"></p><p>如上图两种情况：<br>第一种，左侧a图所示，当一端发送的数据报丢失后要进行重传，到重传之后接收到确认报文之后，这种场景下该如何计算RTT呢？开始时间是按照第一次发送数据报时间呢还是按照重传数据报的时间呢？</p><blockquote><p>w 按照常理来说，如右侧b图所示，RTT时间应该以RTT2为准；</p></blockquote><p>第二种，左侧b图所示，第一次发送数据报文时，由于网络时延导致RTO时间内没有收到接收段的确认报文，发送端进行重发，但是在刚刚重发之后就收到了第一次报文的确认报文，那这种情况RTT该如何计算呢？</p><blockquote><p>w 如右侧a图所示，RTT时间应该以RTT1为准；</p></blockquote><p>就像上面提及的两种情况，一会以第一个RTT1为准，一会以RTT2为准，那么TCP协议如何正确的计算出RTT呢？</p><h2 id="使用Timestamp方式计算RTT"><a href="#使用Timestamp方式计算RTT" class="headerlink" title="使用Timestamp方式计算RTT"></a>使用Timestamp方式计算RTT</h2><p>之前的文章中在介绍TCP超时与重传的笔记中有介绍通过使用Timtstamp的方式来区分相同Seq序列号的不同报文，<br>其实在TCP报文首部存储Timestamp的时候，会存储报文的发送时间和确认时间，如下所示：<br><image src="https://oscimg.oschina.net/oscnet/up-ad80265bbba417c72a8d02a5c0be7be5f83.png" width=800 height=230> </p><h2 id="如何计算RTO？"><a href="#如何计算RTO？" class="headerlink" title="如何计算RTO？"></a>如何计算RTO？</h2><p>上面👆说到了RTT如何计算，那个RTO和RTT有什么关系呢？<br><image src="https://oscimg.oschina.net/oscnet/up-e25afa62f99830eb02c4c1df0c015dbde8a.png"><br> RTO的取值将会影响到TCP的传输效率以及网络的吞吐量；</p><blockquote><p>s 通常来说RTO应该略大于RTT，如果RTO小于RTT，则会造成发送端频繁重发，可能会造成网络阻塞；如果RTO设置的过大，则接受端已经收到确认报文之后的一段时间内仍然不能发送其他报文，会造成两端性能的浪费和网络吞吐量的下降；</p></blockquote><h3 id="平滑RTO"><a href="#平滑RTO" class="headerlink" title="平滑RTO"></a>平滑RTO</h3><p>网络的RTT是不断的变化的，所以计算RTO的时候，应当考虑RTO的平滑性，尽量避免RTT波动带来的干扰，以抵挡瞬时变化；</p><p><strong>平滑RTO在文档RFC793定义，给出如下计算方式：</strong></p><ul><li>SRTT (smoothed round-trip time) = ( α * SRTT ) + ((1 - α) * RTT)<blockquote><p>w α 从 0到 1(RFC 推荐 0.9)，越大越平滑</p></blockquote></li><li>RTO = min[ UBOUND, max[ LBOUND, (β * SRTT) ] ]<blockquote><p>w 如 UBOUND为1分钟，LBOUND为 1 秒钟， β从 1.3 到 2 之间 </p></blockquote></li></ul><p>这种计算方式不适用于 RTT 波动大(方差大)的场景,如果网络的RTT波动很大，会造成RTO调整不及时；</p><h3 id="追踪RTT方差计算RTO"><a href="#追踪RTT方差计算RTO" class="headerlink" title="追踪RTT方差计算RTO"></a>追踪RTT方差计算RTO</h3><blockquote><p>i RFC6298(RFC2988)，其中α = 1/8， β = 1/4，K = 4，G 为最小时间颗粒:</p></blockquote><ul><li><strong>首次计算 RTO，R为第 1 次测量出的 RTT</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SRTT(smoothed round-trip time) = R</span><br><span class="line">RTTVAR(round-trip time variation) = R/2</span><br><span class="line">RTO = SRTT + max (G, K*RTTVAR)</span><br></pre></td></tr></table></figure></li><li><strong>后续计算 RTO，R’为最新测量出的 RTT</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SRTT= (1-α)*SRTT+α*R’</span><br><span class="line">RTTVAR=(1-β)*RTTVAR+β*|SRTT-R’|</span><br><span class="line">RTO = SRTT + max (G, K*RTTVAR)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;i 之前的文章已经介绍了TCP超时重传的过程中使用了定时器的策略，当定时器规定时间内未收到确认报文之后，就会触发报文的重传，同时定时器复位；那么定时器超时时间（RTO Retramission Timeout）是如何计算的呢？&lt;/p&gt;
&lt;/bloc</summary>
      
    
    
    
    <category term="Computer Network" scheme="http://example.com/categories/Computer-Network/"/>
    
    <category term="TCP" scheme="http://example.com/categories/Computer-Network/TCP/"/>
    
    
    <category term="TCP" scheme="http://example.com/tags/TCP/"/>
    
  </entry>
  
</feed>

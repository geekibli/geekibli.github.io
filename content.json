{"pages":[{"title":"About","date":"2021-07-04T09:22:18.003Z","path":"about/index.html","text":""},{"title":"Tags","date":"2021-07-04T07:22:56.335Z","path":"tags/index.html","text":""},{"title":"Categories","date":"2021-07-04T07:22:56.334Z","path":"categories/index.html","text":""}],"posts":[{"title":"拥塞避免","date":"2021-07-04T08:46:13.000Z","path":"wiki/拥塞避免/","text":"拥塞避免拥塞控制的慢启动是以指数方式快速的通过试探来扩大拥塞窗口的，但是一旦发生网络丢包，则肯定是很多报文段都会都是，因为窗口时称被增长的；为了解决这种问题，需要引入– 拥塞避免 什么是拥塞避免拥塞避免为了解决慢启动下，当拥塞窗口超出网络带宽时发生的大量丢包问题，它提出一个「慢启动阈值」的概念，当拥塞窗口到达这个阈值之后，不在以指数方式增长，而选择涨幅比较缓慢的「线性增长」，计算方式： w cwnd += SMSS*SMSS/cwnd 当拥塞窗口在线性增长时发生丢包，将慢启动阈值设置为当前窗口的一半，慢启动窗口恢复初始窗口（init wnd）； i 拥塞避免和慢启动是结合使用的，当发生网络丢包是，拥塞控制采用快速重传和快速启动来解决丢包问题！","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP-四次挥手/断开连接","date":"2021-07-04T08:34:11.000Z","path":"wiki/TCP-四次挥手-断开连接/","text":"TCP断开连接四次挥手 开始客户端和服务端都是处理【established】状态 客户端发送「FIN」报文之后，进入FIN-WAIT-1状态 服务端收到客户端的FIN之后，恢复一个ACK，同时进入CLOSE_WAIT状态 客户端接收到ACK之后，进入到FIN-WAIT-2状态 服务端接着发送FIN报文，同时进入LAST-ACK状态 客户端接收到服务端的FIN报文之后，发送ACK报文，并进入TIME_WAIT状态 客户端在经历2个MSL时间之后，进入CLOSE状态 服务端接收到客户端的ACK之后，进入CLOSE状态 i 并不是所有的四次挥手都是上述流程，当客户端和服务端同时发送关闭连接的请求如下👇： 可以看到双方都主动发起断开请求所以各自都是主动发起方，状态会从 FIN_WAIT_1 都进入到 CLOSING 这个过度状态然后再到 TIME_WAIT。 i 挥手一定需要四次吗？ 假设 client 已经没有数据发送给 server 了，所以它发送 FIN 给 server 表明自己数据发完了，不再发了，如果这时候 server 还是有数据要发送给 client 那么它就是先回复 ack ，然后继续发送数据。等 server 数据发送完了之后再向 client 发送 FIN 表明它也发完了，然后等 client 的 ACK 这种情况下就会有四次挥手。那么假设 client 发送 FIN 给 server 的时候 server 也没数据给 client，那么 server 就可以将 ACK 和它的 FIN 一起发给client ，然后等待 client 的 ACK，这样不就三次挥手了？ i 为什么要有 TIME_WAIT? 断开连接发起方在接受到接受方的 FIN 并回复 ACK 之后并没有直接进入 CLOSED 状态，而是进行了一波等待，等待时间为 2MSL。MSL 是 Maximum Segment Lifetime，即报文最长生存时间，RFC 793 定义的 MSL 时间是 2 分钟，Linux 实际实现是 30s，那么 2MSL 是一分钟。 w 那么为什么要等 2MSL 呢？ 就是怕被动关闭方没有收到最后的 ACK，如果被动方由于网络原因没有到，那么它会再次发送 FIN， 此时如果主动关闭方已经 CLOSED 那就傻了，因此等一会儿。 假设立马断开连接，但是又重用了这个连接，就是五元组完全一致，并且序号还在合适的范围内，虽然概率很低但理论上也有可能，那么新的连接会被已关闭连接链路上的一些残留数据干扰，因此给予一定的时间来处理一些残留数据。 i 等待 2MSL 会产生什么问题？ 如果服务器主动关闭大量的连接，那么会出现大量的资源占用，需要等到 2MSL 才会释放资源。如果是客户端主动关闭大量的连接，那么在 2MSL 里面那些端口都是被占用的，端口只有 65535 个，如果端口耗尽了就无法发起送的连接了，不过我觉得这个概率很低，这么多端口你这是要建立多少个连接？","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"快速重传/快速恢复","date":"2021-07-04T08:33:35.000Z","path":"wiki/快速重传-快速恢复/","text":"快速重传和快速恢复快速重传 d 为何会接收到以个失序数据段？ 若报文丢失，将会产生连续的失序ACK段 若网络路径与设备导致数据段失序，将会产生少量的失序ACK段 若报文重复，将会产生少量的失序ACK段 当发送端发送pkt0是正常的，由于滑动窗口为满，发送方可以继续发送pkt1，pkt2； 加入pkt1发生了丢包，虽然pkt2接收端接收成功了，但是没有pkt1的数据段，接收端还是发送ACK1的确认报文； 在没有「快速重传」的情况下，发送端需要等到RTO之后，才可以重新发送pkt1 重传成功之后，接收端其实收到了pkt2之前的所有数据段，所以发送ACK3的确认报文 w 这种需要等待RTO才可以重传的方式效率是比较低的，因此需要快速重传来进行优化； 快速重传和累积确认 当发送方连续发送pkt3，pkt4，pkt5，pkt6四个数据端，但是pkt5在网络中丢包了，那后面发送的pkt6，pkt7，pkt8的确认报文都返回ACK5，希望发送方吃昂传pkt5的数据段；这个时候，发送方收到连续3个相同的确认报文，便立即重新发送pkt5的数据段； i 接收方: 当接收到一个失序数据段时，立刻发送它所期待的缺口 ACK 序列号 当接收到填充失序缺口的数据段时，立刻发 送它所期待的下一个 ACK 序列号 i 发送方 当接收到3个重复的失序 ACK 段(4个相同的失序ACK段)时，不再等待重传定时器的触发，立刻基于快速重传机制重发报文段 当pkt5重新发送并被接收端接收之后，接收端发送ACK9的确认报文，而不是再分别发送ACK6，ACK7，ACK8，这个称谓「 累计确认 」。 快速恢复 i 快速重传下一定要进入慢启动吗? 接受端收到重复ACK，意味着网络仍在流动，而如果要重新进入慢启动，会导致网络突然减少数据流，拥塞窗口恢复初始窗口，所以，「在快速恢复下发生丢包的场景下」，应该使用快速恢复，简单的讲，就是将慢启动阈值设置成当前拥塞窗口的一半，而拥塞窗口也适当放低，而不是一下字恢复到初始窗口大小； 快速恢复的流程如上图👆所示！ w 快速恢复的具体操作： 将 ssthresh 设置为当前拥塞窗口 cwnd 的一半，设当前 cwnd 为 ssthresh 加上 3*MSS 每收到一个重复 ACK，cwnd 增加 1 个 MSS 当新数据 ACK 到达后，设置 cwnd 为 ssthresh","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP-拥塞控制之慢启动","date":"2021-07-04T08:33:19.000Z","path":"wiki/TCP-拥塞控制之慢启动/","text":"由于TCP是面向字节流的传输协议，可以发送不定长的字节流数据，TCP连接发送数据时会“先天性”尝试占用整个带宽，而当所有的TCP连接都尝试占用网络带宽时，就会造成网络的堵塞，而TCP慢启动算法则是为了解决这一场景； 全局思考 拥塞控制要面向整体思考，如上👆网络拓扑图，当左边的网络节点通过路由交换设备向右边的设备传输报文的时候，中间的某一链路的带宽肯定是一定的，这里假设1000M带宽，当左边R1以700Mb/s的速度向链路中发送数据，同时R2以600Mb/s的速率发送报文，那势必会有300Mb的数据报丢失；「路由交换设备基于存储转发来实现报文的发送」大量报文都是时，路由设备的缓冲队列肯定是慢的，这也会造成某些数据报在网络链路中停留时间过长，从而导致TCP通讯变慢，甚至网络瘫痪； 理想的情况下，当链路带宽占满以后，链路以最大带宽传输数据，当然显示中是不可能的，当发生轻度拥塞时，链路的吞吐量就开始下降了，发展到严重阻塞时，链路的吞吐量会严重地下降，甚至瘫痪； 那么，慢启动是如何发挥作用的呢？ 拥塞窗口 s 拥塞窗口cwnd(congestion window) 通告窗口rwnd(receiver‘s advertised window) 其实就是RCV.WND，标志在TCP首部的Window字段！ 发送窗口swnd = min(cwnd，rwnd) 前面学习滑动窗口的时候提到发送窗口大致等于接受窗口，当引入拥塞窗口时，发送窗口就是拥塞窗口和对方接受窗口的最小值 i 每收到一个ACK，cwnd扩充一倍 慢启动的窗口大小如何设置呢？如上所示，起初拥塞窗口设置成1个报文段大小，当发送端发送一个报文段并且没有发生丢包时，调整拥塞窗口为2个报文段大小，如果还没有发生丢包，一次类推，知道发生丢包停止；发送窗口以「指数」的方式扩大；慢启动是无法确知网络拥塞程度的情况下，以试探性地方式快速扩大拥塞窗口； 慢启动初始窗口慢启动的拥塞窗口真的就如上面所说的以一个报文段大小作为初始值吗？ w 慢启动初始窗口 IW(Initial Window)的变迁 1 SMSS:RFC2001(1997) 2 - 4 SMSS:RFC2414(1998) IW = min (4SMSS, max (2SMSS, 4380 bytes)) 10 SMSS:RFC6928(2013) IW = min (10MSS, max (2MSS, 14600)) w 其实在实际情况下，互联网中的网页都在10个mss左右，如果还是从1个mss开始，则会浪费3个RTT的时间；","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP-如何减少小报文提升网络效率","date":"2021-07-04T08:32:55.000Z","path":"wiki/TCP-如何减少小报文提升网络效率/","text":"如何减少小报文提升网络效率每一个TCP报文段都包含20字节的IP头部和20字节的TCP首部，如果报文段的数据部分很少的话，网络效率会很差； SWS(Silly Window syndrome) 糊涂窗口综合症 如上图👆所示场景，在之前的滑动窗口已经了解过，随着服务端处理连接数据能力越来越低，服务端的可用窗口不断压缩，最终导致窗口关闭； SWS 避免算法SWS 避免算法对发送方和接收方都做客 接收方 i David D Clark 算法:窗口边界移动值小于 min(MSS, 缓存/2)时，通知窗口为 0 发送方 w Nagle 算法:1、TCP_NODELAY 用于关闭 Nagle 算法2、没有已发送未确认报文段时，立刻发送数据3、存在未确认报文段时，直到:1-没有已发送未确认报文段，或者 2-数据长度达到MSS时再发送 TCP delayed acknowledgment 延迟确认实际情况下，没有携带任何数据的ACK报文也会造成网络效率低下的，因为确认报文也包含40字节的头部信息，但仅仅是为了传输ACK=1这样的信息，为了解决这种情况，TCP有一种机制，叫做延迟确认，如下👇： 当有响应数据要发送时,ack会随着响应数据立即发送给对方. 如果没有响应数据,ack的发送将会有一个延迟,以等待看是否有响应数据可以一起发送 如果在等待发送ack期间,对方的第二个数据段又到达了,这时要立即发送ack 那个延迟的时间如何设置呢？ 上面👆是Linux操作系统对于TCP延时的定义。 HZ是什呢？其实那是和操作系统的时钟相关的，具体的操作系统间各有差别；如何查看Linux操作系统下的HZ如何设置呢？ 1cat /boot/config- `-uname -r` | grep &#x27;^GONFIG_HZ=&#x27; TCP_CORK sendfile 零拷贝技术","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP-滑动窗口","date":"2021-07-04T08:32:40.000Z","path":"wiki/TCP-滑动窗口/","text":"滑动窗口 i 之前学习了PAR方式的TCP超时和重传，其实在考虑发送方发送数据报的同时，也应该考虑接收方对于数据的处理能力，由此引出本次学习的主题 – 滑动窗口 发送端窗口滑动窗口按照传输数据方向分为两种，发送端窗口和接收端窗口；下面先看一下发送端窗口👇： 上图分为四个部分： 已发送并收到 Ack 确认的数据:1-31 字节 已发送未收到 Ack 确认的数据:32-45 字节 未发送但总大小在接收方处理范围内:46-51 字节 未发送但总大小超出接收方处理范围:52-字节 可用窗口和发送窗口 如上图这里可以引出两个概念：「可用窗口」和「发送窗口」 s 【 可用窗口 】： 就是上图中的第三部分，属于还未发送，但是在接收端可以处理范围内的部分；【 发送窗口 】： 就是发送端可以发送的最大报文大小，如上图中的第二部分+第三部分合成发送窗口； 可用窗口耗尽 可用窗口会在一个短暂的停留，当处于未发送并且接受端可以接受范围内的数据传输完成之后，可用窗口耗尽；当然上面仅仅说的一瞬时的状态，这个状态下，已经发送的报文段还没有确认，并且发送窗口大小没有发生变化，此时发送窗口达到最大状态； 窗口移动 如果在发送窗口中已经发送的报文段已经得到接受端确认之后，那部分数据就会被移除发送窗口，在发送窗口大小不发生变化的情况下，发送窗口向右➡️移动5个字节，因为左边已经发送的5个字节得到确认之后，被移除发送窗口； 可用窗口如何计算 再次引出三个概念： SND.WND i SND 指的是发送端，WND指的是window，也就是发送端窗口的意思 SND.UNA i UNA 就是un ACK的意思，指的是已经发送但是没有没有确认 它指向窗口的第一个字节处 SND.NXT i NXT 是next的位置，是发送方接下来要发送的位置，它指向可用窗口的第一个字节处 那就很容易得出可用窗口的大小了，计算公式如下： i Usable Window Size = SND.UNA + SND.WND - SND.NXT 接收端窗口上面介绍了发送端窗口的一些概念，下面👇是接收端窗口的学习： 已经接收并且已经确认 :28-31 字节 还未接收并且接收端可以接受:32-51 字节 还未接收并且超出接收处理能力:51-57 字节 这里引出两个概念： RCV.WND i RCV是接收端的意思，WND是接受端窗口的大小 RCV.NXT i NXT表示的是接受端接收窗口的开始位置，也就是接收方接下来处理的第一个字节； RCV.WND的大小接受端的内存以及缓冲区大小有关，在某种意义上说，接受端的窗口大小和发送端大小大致相同；接受端可接收的数据能力可以通过TCP首部的Window字段设置，但是接受端的处理能力是可能随时变化的，所以接受端和服务端的窗口大小大致是一样的； 流量控制下面👇根据一个例子来阐述流量控制，模拟一个GET请求，客户端向服务端请求一个260字节的文件，大致流程如下，比较繁琐： s 这里假设MSS和窗口的大小不发生变化，同时客户端和发送端状态如下：【 客户端 】： 发送窗口默认360字节 接收窗口设定200字节【 服务端 】： 发送窗口设定200字节 接收窗口设定360字节 Step1： 客户端发送140字节的数据到服务端 i 【客户端】发送140字节，【SND.NXT】从1-&gt;141 w 【服务端】状态不变，等待接收客户端传输的140字节 Step2: 服务端接收140字节，发送80字节响应以及ACK i 【 客户端 】发送140字节之后等待【 服务端 】的ACK w【 服务端 】可用窗口右移，【RCV.NXT】从1-&gt;141【 服务端 】发送80字节数据，【SND.NXT】从241-&gt;321 Step3: 客户端接收响应ACK，并且发送ACK i 【 客户端 】发出的140字节得到确认，【SND.UNA】右移140字节【 客户端 】接收80字节数据，【RCV.NXT】右移80字节，从241-&gt;321 Step4: 服务端发送一个280字节的文件，但是280字节超出了客户端的接收窗口，所以客户端分成两部分传输，先传输120字节； w 【 服务端 】发送120字节，【SND.NXT】向右移动120字节，从321-&gt;441 Step5: 客户端接收文件第一部分，并发送ACK i 【 客户端 】接收120字节，【RCV.NXT】从321-&gt;441 Step6：服务端接收到第二步80字节的ACK w [ 服务器 ] 80字节得到ACK 【SND.UNA】从241-&gt;321 Step7: 服务端接收到第4步的确认 w 【 服务端 】之前发送文件第一部分的120字节得到确认，【SND.UNA】右移动120，从321-&gt;441 Step8: 服务端发送文件第二部分的160字节 w 【 服务端 】： 发送160字节，【SND.NXT】向右移动160字节，从441-&gt;601 Step9: 客户端接收到文件第二部分160字节，同时发送ACK i 【 客户端 】接收160字节，【RCV.NXT】向右移动160字节，从441-&gt;601 Step10: 服务端收到文件第二部分的ACK w 【 服务端 】发送的160字节得到确认，【SND.UNA】向右一定160字节，从441-&gt;601；至此客户端收到服务端发送的完整的文件； 上面通过表格列举服务端和客户端每个状态在每个步骤的状态，如果不是很好理解，可以看如下示意图辅助理解： 客户端交互流程 服务端交互流程 上面👆是模拟一个GET请求，服务端发送一个280字节的文件给到客户端，客户端的接收窗口是200字节场景加，客户端和服务端的数据传输与交互流程，通过这个流程来学习滑动窗口的移动状态和流量控制的大致流程； 滑动窗口与操作系统缓冲区上面👆讲述的时候，都是假设窗口大小是不变的，而实际上，发送端和接受端的滑动窗口的字节数都吃存储在操作系统缓冲区的，操作系统的缓冲区受操作系统控制，当应用进程增加是，每个进程分配的内存减少，缓冲区减少，分配给每个连接的窗口就会压缩。**而且滑动窗口的大小也受应用进程读取缓冲区数据速度有关**； 应用进程读取缓冲区数据不及时造成窗口收缩step1: 客户端发送140字节 i 客户端发送到140字节之后，可用窗口收缩到220字节，发送窗口不变 Step2: 服务端接收140字节 但是应用进程仅仅读取40字节 w 服务端应用进程仅仅读取40字节，仍有100字节占用缓冲区大小，导致接受窗口收缩，服务端发送ACK报文时，在首部Window带上接收窗口的大小260 Step3: 客户端收到确认报文之后，发送窗口收缩到260 Step4: 客户端继续发送180字节数据 i 客户端发送180字节之后，可用窗口变成80字节 Step5: 服务端接收到180字节 w 假设应用程序仍然不读取这180字节，最终也导致服务端接收窗口再次收缩180字节，仅剩下80字节，在发送确认报文时，设置首部window=80 Step6: 客户端收到80字节的窗口时，调整发送窗口大小为80字节，可用窗口也是80字节 Step7: 客户端仍然发送80字节到服务端，此时可用窗口为空 Step8: 服务端应用进程继续不读区这80字节的缓冲区数据，最终导致服务端接收窗口大小为0，不能再接收任何数据，同时发送ACK报文； Step9：客户端收到确认报文之后，调整发送窗口大小为0，这个状态叫做「 窗口关闭 」 窗口收缩导致的丢包 Step1：客户端服务端开始的窗口大小都是360字节，客户端发送140字节数据 i 客户端发送140字节之后，可用窗口变成220字节 Step2：服务端应用进程骤增，进程缓存区平均分配，造成服务端接收窗口减少，从360变成240字节； w 假设接收了140字节之后，应用进程没有读取，那个可用窗口进一步压缩，变成100字节； Step3：假设同一个连接在没有收到服务端确认之后，又发送了180个字节的数据（Retramission） i 先发送了140字节，后发送了180字节，都没有得到确认，客户端可用窗口大小变成40字节 Step4：服务端收到上面👆第三步发送的180字节的数据，但是接受窗口的大小只有100字节，所以不能接收 w 服务端拒绝接收180字节 Step5：此时客户端才收到之前140字节的确认报文，才知道接收窗口发生了变化 i 客户端由于没有收到180字节的确认，加入客户端正在准备发送180字节数据，得到接受端的窗口大小是100字节之后，须强制将右侧窗口向左收缩80字节； 窗口关闭这个例子和上面的例子都发生了「 窗口关闭 」 s 窗口关闭： 发送端的发送窗口变成0的状态； 上面讲的两种情况一般不会发生的，因为操作系统不会既收缩窗口，同时减少连接缓存；而是一般先使用窗口收缩策略，之后在压缩缓冲区的方式来规避以上问题；发生窗口关闭之后，发送端不会被动的等待服务端的通知，而是会采用定时嗅探的方式去查看服务端接收窗口是否开放； Linux中对TCP缓冲区的调整方式 net.ipv4.tcp_rmem = 4096 87380 6291456 读缓存最小值、默认值、最大值，单位字节，覆盖 net.core.rmem_max net.ipv4.tcp_wmem = 4096 16384 4194304 写缓存最小值、默认值、最大值，单位字节，覆盖net.core.wmem_max net.ipv4.tcp_mem = 1541646 2055528 3083292 系统无内存压力、启动压力模式阀值、最大值，单位为页的数量 net.ipv4.tcp_moderate_rcvbuf = 1 开启自动调整缓存模式","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP-RTO重传计数器的计算","date":"2021-07-04T08:32:27.000Z","path":"wiki/TCP-RTO重传计数器的计算/","text":"i 之前的文章已经介绍了TCP超时重传的过程中使用了定时器的策略，当定时器规定时间内未收到确认报文之后，就会触发报文的重传，同时定时器复位；那么定时器超时时间（RTO Retramission Timeout）是如何计算的呢？ 什么是RTT？了解RTO如何计算之前，首先明确一个概念「 RTT 」； 如上图所示，从client发送第一个「SYN」报文，到Server接受到报文，并且返回「SYN ACK」报文之后，client接受到Server的「ACK」报文之后，client所经历的时间，叫做1个RTT时间； 如何在重传下有效测量RTT？ 如上图两种情况：第一种，左侧a图所示，当一端发送的数据报丢失后要进行重传，到重传之后接收到确认报文之后，这种场景下该如何计算RTT呢？开始时间是按照第一次发送数据报时间呢还是按照重传数据报的时间呢？ w 按照常理来说，如右侧b图所示，RTT时间应该以RTT2为准； 第二种，左侧b图所示，第一次发送数据报文时，由于网络时延导致RTO时间内没有收到接收段的确认报文，发送端进行重发，但是在刚刚重发之后就收到了第一次报文的确认报文，那这种情况RTT该如何计算呢？ w 如右侧a图所示，RTT时间应该以RTT1为准； 就像上面提及的两种情况，一会以第一个RTT1为准，一会以RTT2为准，那么TCP协议如何正确的计算出RTT呢？ 使用Timestamp方式计算RTT之前的文章中在介绍TCP超时与重传的笔记中有介绍通过使用Timtstamp的方式来区分相同Seq序列号的不同报文，其实在TCP报文首部存储Timestamp的时候，会存储报文的发送时间和确认时间，如下所示： 如何计算RTO？上面👆说到了RTT如何计算，那个RTO和RTT有什么关系呢？ RTO的取值将会影响到TCP的传输效率以及网络的吞吐量； s 通常来说RTO应该略大于RTT，如果RTO小于RTT，则会造成发送端频繁重发，可能会造成网络阻塞；如果RTO设置的过大，则接受端已经收到确认报文之后的一段时间内仍然不能发送其他报文，会造成两端性能的浪费和网络吞吐量的下降； 平滑RTO网络的RTT是不断的变化的，所以计算RTO的时候，应当考虑RTO的平滑性，尽量避免RTT波动带来的干扰，以抵挡瞬时变化； 平滑RTO在文档RFC793定义，给出如下计算方式： SRTT (smoothed round-trip time) = ( α * SRTT ) + ((1 - α) * RTT) w α 从 0到 1(RFC 推荐 0.9)，越大越平滑 RTO = min[ UBOUND, max[ LBOUND, (β * SRTT) ] ] w 如 UBOUND为1分钟，LBOUND为 1 秒钟， β从 1.3 到 2 之间 这种计算方式不适用于 RTT 波动大(方差大)的场景,如果网络的RTT波动很大，会造成RTO调整不及时； 追踪RTT方差计算RTO i RFC6298(RFC2988)，其中α = 1/8， β = 1/4，K = 4，G 为最小时间颗粒: 首次计算 RTO，R为第 1 次测量出的 RTT123SRTT(smoothed round-trip time) = RRTTVAR(round-trip time variation) = R/2RTO = SRTT + max (G, K*RTTVAR) 后续计算 RTO，R’为最新测量出的 RTT123SRTT= (1-α)*SRTT+α*R’RTTVAR=(1-β)*RTTVAR+β*|SRTT-R’|RTO = SRTT + max (G, K*RTTVAR)","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP超时与重传","date":"2021-07-04T08:32:08.000Z","path":"wiki/TCP超时与重传/","text":"背景 如上图👆所示，设备A向设备B发送消息，消息在网络中会由于各种各样的问题导致丢失，那么该如何解决上述问题呢？ 采用定时器重传 i PAR：Positive Acknowledgment with Retransmission 最简单的思路是在发送方设置「 定时器 」： 当设备A发送第一条消息之后，在定时器规定的时间内，如果收到设备B的确认报文，则设备A继续发送下一个报文，同时定时器复位； 如果第一条消息发送时间超出了定时器规定的时间，则设备A将重新发送第一条消息，同时重新设置定时器； 这种方式是串型发送的，只有第一个消息发送成功之后，才可以发送下一条消息，「 效率极差 」； 并发能力PAR i 基于上述PAR效率低下的方式进行改造，在发送端采用并发+定时器的方式进行数据发送； 首先设备A可以同时发送多个消息或者报文段，每个报文段具有一个标志字段【#XX】去标志唯一，每个报文段连接具有自己的定时器； 设备B规定时间内收到设备A发送的数据之后并且设备A得到设备B的确认之后，设备A将定时器清除 同PAR一样，设备B没有在规定的时间内发送确认报文，设备A将这个报文所对应的定时器复位，重新发送这个报文 并发发送带来的问题采用并发的方式发送消息或者报文段固然提升了发送端的性能，但是发送端发送的消息可能接受端不能完全处理，这是双方报文处理速度或者效率不一致的问题； 所以对于接收端设备B，应该明确自己可能接受的数据量，并且在确认报文中同步到发送端设备A，设备A根据设备B的处理能力来调整发送数据的大小；也就是上图中的「 limit」； 继续延伸Sequment序列号和Ack序列号的设计理念或者设计初衷是「 解决应用层字节流的可靠发送 」 跟踪「应用层」的发送端数据是否送达 确定「接收端有序的」接收到「字节流」 序列号的值针对的是字节而不是报文 ⚠️⚠️⚠️ i TCP的定位就是面向字节流的！ TCP序列号如何设计的 通过TCP报文头我们可以知道，Sequment序列号包括32位长度；也就是说一个Sequment可以发送2的32次方个字节，大约4G的数量，Sequment就无法表示了，当传输的数据超过“4G”之后，如果这个连接依然要使用的话，Sequment会重新复用；Sequment复用会产生一个问题，也就是序列号回绕；👇 序列号回绕 i 序列号回绕 (Protect Against Wrapped Sequence numbers) 当一个连接要发送6G的数据是，A、B、C、D分别发送1G的数据，如果继续使用此连接，E下一次发送数据1G，Seq序列号复用，E报文段的序列号和A报文段的序列号表示相同 按照上面的逻辑继续发送数据，F报文段的Seq标志和B报文段的是一样的； 加入B报文段在发送过程中丢失了，直到接受端接收了F报文段的同时B报文段到达接受端，接受端该如何区分相同Seq序列号不同数据的报文段呢？ 其实TCP解决这个问题很简单，就是在每个报文段上添加Tcp Timestamp时间戳，类似于版本号的理念； 接收端收到相同Seq序列号的报文段是可以根据时间戳来进行区分；","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP最大报文段（MSS）","date":"2021-07-04T08:31:56.000Z","path":"wiki/TCP最大报文段（MSS）/","text":"MSS产生的背景我们都知道TCP协议是运输在传输层的协议，它是面向【字节流】的传输协议；它的上层，应用层传输的数据是无限制的，但是它的下层也就是网络层和链路层由于路由等转发设备有内存等限制是不可能无限制传输任何大小的报文的，它们一定会限制报文的长度，因此 TCP协议要完成的工作是将从应用层接受到的任意长度数据，切割成多个报文段，MSS就是如何切割报文段的依据。 什么是MSSMSS（Max Segment Size）：仅指 TCP 承载数据，不包含 TCP 头部的大小，参见 RFC879 MSS 选择目的 尽量每个 Segment 报文段携带更多的数据，以减少头部空间占用比率 防止 Segment 被某个设备的 IP 层基于 MTU 拆分 s IP层基于MTU的数据拆分是效率极差的，一个报文段丢失，所有的报文段都要重传 MSS默认大小 s 默认 MSS:536 字节(默认 MTU576 字节，20 字节 IP 头部，20 字节 TCP 头部) MSS在什么时候使用 s 握手阶段协商 MSS 这个在TCP三次握手的文章中已经提及过了！ MSS 分类 发送方最大报文段: SMSS:SENDER MAXIMUM SEGMENT SIZE 接收方最大报文段: RMSS:RECEIVER MAXIMUM SEGMENT SIZE 在TCP常用选项中可以看到【MSS】的选项 TCP流与报文段在数据传输中的状态 从上图可以看到，左边客户端在发送字节流数据给到右边客户端，客户端发送一个连续的字节流，会在TCP层按照MSS大小规定进行拆分成多个小的报文段，分别传送到另一个客户端或者其他的接收端；","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP三次握手","date":"2021-07-04T08:31:42.000Z","path":"wiki/TCP三次握手/","text":"握手🤝的目的 同步Sequence序列号 i 初始化序列号ISN （Inital Sequence Number） 交换TCP通讯的参数 i 比如最大报文段参数（MSS）、窗口比例因子（Window）、选择性确认（SACK）、制定校验和算法； 三次握手握手过程 TCP三次握手的大致流程图如上👆 使用tcpdump抓包分析三次🤝握手报文中Seq和Ack的变化 1tcpdump port 80 -c 3 -S 第一次握手🤝1IP upay.60734 &gt; 100.100.15.23.http: Flags [S], seq 3800409106, win 29200, options [mss 1460,sackOK,TS val 839851765 ecr 0,nop,wscale 7], length 0 客户端upay访问服务端80端口，发送一个「 seq=3800409106 」 ，同时标志位SYN=1，声明此次握手是要建立连接； 第二次握手🤝1IP 100.100.15.23.http &gt; upay.60734: Flags [S.], seq 1981710286, ack 3800409107, win 14600, options [mss 1440,nop,nop,sackOK,nop,wscale 7], length 0 第二次握手，服务端收到客户端的申请连接强求（SYN=1）之后，在服务端自己准备好的情况下，给客户端发送 「 ACK=1 SYN=1 」的确认报文，SYN=1同样也是声明此次报文是建立连接的报文请求； ack= 3800409107 也就是第一个客户端发给服务端的seq+1（ack是接收方下次期望接口报文的开始位置） 第三次握手握手1IP upay.60734 &gt; 100.100.15.23.http: Flags [.], ack 1981710287, win 229, length 0 客户端收到服务器返回的确认报文，确认可以进行连接，发送「 ack = 1981710287 」的确认报文，之后就完成了三次握手，TCP的连接就创建成功了，接下来双方就可以发送数据报了； TCP连接创建构成中状态的变更 首先客户端和服务端都是【CLOSED】状态，客户端发起连接请求之后，进入【SYN-SENT】状态，这个状态维持的时间很短，我们使用netstat去查看tcp连接状态的时候，基本上都不会看到这个状态，而服务端是在【LISTEN】状态，等待客户端的请求； 服务端收到客户端请求之后，发送「SYN ACK」确认报文，同时服务端进入【SYN-RECEIVED】状态，等待客户端的确认报文； 客户端收到服务端的同步确认请求之后，发送「ACK」确认报文，同时进入【ESTABLISHED】状态，准备后续的数据传输； 服务端收到三次握手最后的确认报文之后，进入【ESTABLISHED】状态，至此，一个TCP连接算是建立完成了，后面就是双方的通信了； TCB（Transmission Control Block） i 保存连接使用的源端口、目的端口、目的 ip、序号、 应答序号、对方窗口大小、己方窗口大小、tcp 状态、tcp 输入/输出队列、应用层输出队 列、tcp 的重传有关变量等 TCP性能优化和安全问题 正如我们了解的TCP三次握手🤝的流程，当有大量SYN请求到达服务端时，会进入到【SYN队列】，服务端收到第二次确认报文之后，会进入【ESTABLISHED】状态，服务端操作系统内核会将连接放入到【ACCEPT】队列中，当Nginx或者Tomcat这些应用程序在调用accept（访问内核）的时候，就是在【ACCEPT】队列中取出连接进行处理； w 由此可见，【SYN】队列和【ACCEPT】是会影响服务器连接性能的重要因素，所以对于高并发的场景下，这两个队列一定是要设置的比较大的； 如何设置SYN队列大小服务器端 SYN_RCV 状态 net.ipv4.tcp_max_syn_backlog:SYN_RCVD 状态连接的最大个数 net.ipv4.tcp_synack_retries:被动建立连接时，发SYN/ACK的重试次数 客户端 SYN_SENT 状态（服务端作为客户端，比如Ngnix转发等） net.ipv4.tcp_syn_retries = 6 主动建立连接时，发 SYN 的重试次数 net.ipv4.ip_local_port_range = 32768 60999 建立连接时的本地端口可用范围 Fast Open机制 TCP如何对连接的次数以及连接时间进行优化的呢？这里提到Fast Open机制；比如我们有一个Http Get请求，正常的三次握手🤝到收到服务端数据需要2个RTT的时间；FastOpen做出如下优化： 第一次创建连接的时候，也是要经历2个RTT时间，但是在服务端发送确认报文的时候，在报文中添加一个cookie； 等到下次客户端再需要创建请求的时候，直接将【SYN】和cookie一并带上，可以一次就创建连接，经过一个RTT客户端就可以收到服务端的数据； 如何Linux上打开TCP Fast Open net.ipv4.tcp_fastopen:系统开启 TFO 功能 0:关闭 1:作为客户端时可以使用 TFO 2:作为服务器时可以使用 TFO 3:无论作为客户端还是服务器，都可以使用 TFO SYN攻击什么是SYN攻击？ 正常的服务通讯都是由操作系统内核实现的请求报文来创建连接的，但是，可以人为伪造大量不同IP地址的SYN报文，也就是上面👆状态变更图中的SYN请求，但是收到服务端的ACK报文之后，却不发送对于服务端的ACK请求，也就是没有第三次挥手，这样会造成大量处于【SYN-RECEIVED】状态的TCP连接占用大量服务端资源，导致正常的连接无法创建，从而导致系统崩坏； SYN攻击如何查看1netstat -nap | grep SYN_RECV w 如果存在大量【SYN-RECEIVED】的连接，就是发生SYN攻击了； 如何规避SYN攻击？ net.core.netdev_max_backlog 接收自网卡、但未被内核协议栈处理的报文队列长度 net.ipv4.tcp_max_syn_backlog SYN_RCVD 状态连接的最大个数 net.ipv4.tcp_abort_on_overflow 超出处理能力时，对新来的 SYN 直接回包 RST，丢弃连接 设置SYN Timeout 由于SYN Flood攻击的效果取决于服务器上保持的SYN半连接数，这个值=SYN攻击的频度 x SYN Timeout，所以通过缩短从接收到SYN报文到确定这个报文无效并丢弃改连接的时间，例如设置为20秒以下，可以成倍的降低服务器的负荷。但过低的SYN Timeout设置可能会影响客户的正常访问。 设置SYN Cookie (net.ipv4.tcp_syncookies = 1) 就是给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，并记录地址信息，以后从这个IP地址来的包会被一概丢弃。这样做的结果也可能会影响到正常用户的访问。 当 SYN 队列满后，新的 SYN 不进入队列，计算出 cookie 再 以 SYN+ACK 中的序列号返回客户端，正常客户端发报文时， 服务器根据报文中携带的 cookie 重新恢复连接 w 由于 cookie 占用序列号空间，导致此时所有 TCP 可选 功能失效，例如扩充窗口、时间戳等 TCP_DEFER_ACCEPT这个是做什么呢？ 正如上面👆操作系统内核展示图所示，内核中维护两个队列【SYN】队列和【ACCEPT】队列，只有当收到客户端的ACK报文之后，连接会进入到【ACCEPT】，同时服务器的状态是【ESTABLISHED】状态，此时操作系统并不会去激活应用进程，而是会等待，知道收到真正的data分组之后，才会激活应用进程，这是为了提高应用进程的执行效率，避免应用进程的等待； i TCP三次握手为什么不能是两次或者四次 参见文章：敖丙用近 40 张图解被问千百遍的 TCP 三次握手和四次挥手面试题","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP头部","date":"2021-07-04T08:31:22.000Z","path":"wiki/TCP头部/","text":"带着问题学习 如何校验报文段是否损坏？ 如何CRC校验 seq和ack是如何计算的？ tcp校验位都有那些？ 6个 分别是什么含义？ tcp如何计算首部长度？ 偏移量 TCP Retransmission 重传？ tcp spurious retransmission 又是什么呢？ tcp dup ack 是什么？ ack与ACK有什么区别？ 分别有什么作用？ TCP头部结构 学习TCP协议首先要看一下它的报文段是如何组成的；TCP报文段组成由两部分，第一部分是报文头部，第二部分是数据部分； 先看一下报文头，也就是TCP首部的组成； 16位端口16位端口号：告知主机该报文段是来自哪里（源端口Source Port）以及传给哪个上层协议或应用程序（目的端口Destination Port）的。进行TCP通信时，客户端通常使用系统自动选择的临时端口号，而服务器则使用知名服务端口号（比如DNS协议对应端口53，HTTP协议对应80，这些端口号可在/etc/services文件中找到）。 序列号（Seq）占32位，也就是4字节长度，序号范围自然也是是0~2^32-1。TCP是面向字节流的，TCP连接中传送的字节流中的每个字节都按顺序编号。整个要传送的字节流的起始序号必须要在连接建立时设置。首部中的序号字段值指的是本报文段所发送的数据的第一个字节的序号。 TCP用序列号对数据包进行标记，以便在到达目的地后重新重装，假设当前的序列号为 s，发送数据长度为 l，则下次发送数据时的序列号为 s + l。在建立连接时通常由计算机生成一个随机数作为序列号的初始值。 **这里存在一个疑问，第一次建立TCP连接的时候，网上一些博客上说seq是client随机生成的，也有的博客说是seq=1； 这里经过我抓包后，看到第一次创建TCP连接的时候，确实是1; ** 确认应答号（Ack）Ack占32位，4个字节长度，表示期望收到对方下一个报文段的序号值。 用作对另一方发送来的TCP报文段的响应。其值是收到的TCP报文段的序号值加1。假设主机A和主机B进行TCP通信，那么A发送出的TCP报文段不仅携带自己的序号，而且包含对B发送来的TCP报文段的确认号。反之，B发送出的TCP报文段也同时携带自己的序号和对A发送来的报文段的确认号。TCP的可靠性，是建立在「每一个数据报文都需要确认收到」的基础之上的。 就是说，通讯的任何一方在收到对方的一个报文之后，都要发送一个相对应的「确认报文」，来表达确认收到。 那么，确认报文，就会包含确认号。 若确认号=N，则表明：到序号N-1为止的所有数据都已正确收到。 数据偏移 Offset占 0.5 个字节 (4 位)。 这个字段实际上是指出了TCP报文段的首部长度 ，它指出了TCP报文段的数据起始处距离TCP报文的起始处有多远。 注意数据起始处和报文起始处的意思，上面👆已经写到，TCP报文段的组成有两部分，TCP报文首部和数据部分，偏移量记录的是报文段开始和数据开始的长度，也就是报文首部的长度； 一个数据偏移量 = 4 byte，由于4位二进制数能表示的最大十进制数字是 15，因此数据偏移的最大值是 60 byte，这也侧面限制了TCP首部的最大长度。 保留Reserved占 0.75 个字节 (6 位)。 保留为今后使用，但目前应置为 0。 标志位 TCP Flags标志位，一共有6个，分别占1位，共6位。 每一位的值只有 0 和 1，分别表达不同意思。 如上图是使用wireshard抓包展示截图； ACK(Acknowlegemt) ：确认序号有效 当 ACK = 1 的时候，确认号（Acknowledgemt Number）有效。 一般称携带 ACK 标志的 TCP 报文段为「确认报文段」。为0表示数据段不包含确认信息，确认号被忽略。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 设置为 1。 RST(Reset)：重置连接 当 RST = 1 的时候，表示 TCP 连接中出现严重错误，需要释放并重新建立连接。 一般称携带 RST 标志的 TCP 报文段为「复位报文段」。 SYN(SYNchronization)：发起了一个新连接 当 SYN = 1 的时候，表明这是一个请求连接报文段。 一般称携带 SYN 标志的 TCP 报文段为「同步报文段」。 在 TCP 三次握手中的第一个报文就是同步报文段，在连接建立时用来同步序号。对方若同意建立连接，则应在响应的报文段中使 SYN = 1 和 ACK = 1。 PSH (Push): 推送 当 PSH = 1 的时候，表示该报文段高优先级，接收方 TCP 应该尽快推送给接收应用程序，而不用等到整个 TCP 缓存都填满了后再交付。 FIN：释放一个连接 当 FIN = 1 时，表示此报文段的发送方的数据已经发送完毕，并要求释放 TCP 连接。一般称携带 FIN 的报文段为「结束报文段」。在 TCP 四次挥手释放连接的时候，就会用到该标志。 窗口大小 Window Size占16位。该字段明确指出了现在允许对方发送的数据量，它告诉对方本端的 TCP 接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。 窗口大小的值是指，从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。 例如，假如确认号是701，窗口字段是 1000。这就表明，从 701 号算起，发送此报文段的一方还有接收 1000 （字节序号是 701 ~ 1700） 个字节的数据的接收缓存空间。 校验和 TCP Checksum占16位。 由发送端填充，接收端对TCP报文段执行【CRC算法】，以检验TCP报文段在传输过程中是否损坏，如果损坏这丢弃。 检验范围包括首部和数据两部分，这也是 TCP 可靠传输的一个重要保障。 紧急指针 Urgent Pointer占 2 个字节。 仅在 URG = 1 时才有意义，它指出本报文段中的紧急数据的字节数。 当 URG = 1 时，发送方 TCP 就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。 因此，紧急指针指出了紧急数据的末尾在报文段中的位置。 选项 每个选项开始是1字节kind字段，说明选项的类型 kind为0和1的选项，只占一个字节 其他kind后有一字节len，表示该选项总长度（包括kind和len） kind为11，12，13表示tcp事务 下面是常用选项： MTU（最大传输单元）MTU（最大传输单元）是【链路层】中的网络对数据帧的一个限制，以以太网为例，MTU 为 1500 个字节。一个IP 数据报在以太网中传输，如果它的长度大于该 MTU 值，就要进行分片传输，使得每片数据报的长度小于MTU。分片传输的 IP 数据报不一定按序到达，但 IP 首部中的信息能让这些数据报片按序组装。IP 数据报的分片与重组是在网络层进完成的。 MSS （最大分段大小）MSS 是 TCP 里的一个概念（首部的选项字段中）。MSS 是 TCP 数据包每次能够传输的最大数据分段，TCP 报文段的长度大于 MSS 时，要进行分段传输。TCP 协议在建立连接的时候通常要协商双方的 MSS 值，每一方都有用于通告它期望接收的 MSS 选项（MSS 选项只出现在 SYN 报文段中，即 TCP 三次握手的前两次）。MSS 的值一般为 MTU 值减去两个首部大小（需要减去 IP 数据包包头的大小 20Bytes 和 TCP 数据段的包头 20Bytes）所以如果用链路层以太网，MSS 的值往往为 1460。而 Internet 上标准的 MTU 为 576，那么如果不设置，则MSS的默认值就为 536 个字节。TCP报文段的分段与重组是在运输层完成的。 seq和ack的计算逻辑 CRC校验参考资料TCP协议中的seq/ack序号是如何变化的？TCP协议详解TCP协议详解（一）：TCP头部结构TCP和UDP报文头格式TCP协议详解吃透TCP协议","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"TCP协议","date":"2021-07-04T08:30:55.000Z","path":"wiki/TCP协议/","text":"TCP协议学习笔记📒 w 下面是本人在学习TCP协议的过程中，记录的笔记，按照学习的过程从前到后整理在这里！可能会有很多的知识没有罗列，只是记录的大概框架，如果有问题或错误，欢迎指正！ 1、TCP报文头部2、TCP三次握手3、TCP最大报文段（MSS）4、TCP超时与重传5、RTO重传计时器的计算6、滑动窗口7、提升网络效率8、TCP拥塞控制之慢启动9、TCP拥塞控制之拥塞避免10、快速重传与快速恢复11、四次挥手 学习资料 i 敖丙Github整理的笔记 有大概10篇左右的文章，都是高质量的，原地址请点击着👉 【Github】 i 极客时间《Web协议详解与抓包实战》– 陶辉老师 这门课程专门讲解网络协议的，包括Http/Https,TLS协议，TCP协议，IP协议等； i 《计算机网络 自顶向下方法》第7版 很多名校计算机网络课程在使用的教材，非常权威！","tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"}]},{"title":"Welcome to GeekIBLi","date":"2021-07-04T07:44:33.000Z","path":"wiki/index/","text":"I am geekibli; I come from HBU. I like code. 😄😄😄😄","tags":[],"categories":[{"name":"Overview","slug":"Overview","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Overview/"}]}],"categories":[{"name":"Computer Network","slug":"Computer-Network","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/"},{"name":"TCP","slug":"Computer-Network/TCP","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Computer-Network/TCP/"},{"name":"Overview","slug":"Overview","permalink":"https://geekibli.github.io/geekibli.github.io/categories/Overview/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://geekibli.github.io/geekibli.github.io/tags/TCP/"}]}